"use strict";(self.webpackChunkzio_site=self.webpackChunkzio_site||[]).push([[38270],{3905:(e,t,a)=>{a.d(t,{Zo:()=>c,kt:()=>k});var n=a(67294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),p=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},c=function(e){var t=p(e.components);return n.createElement(s.Provider,{value:t},e.children)},d="mdxType",m={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},u=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,c=l(e,["components","mdxType","originalType","parentName"]),d=p(a),u=r,k=d["".concat(s,".").concat(u)]||d[u]||m[u]||o;return a?n.createElement(k,i(i({ref:t},c),{},{components:a})):n.createElement(k,i({ref:t},c))}));function k(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,i=new Array(o);i[0]=u;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l[d]="string"==typeof e?e:r,i[1]=l;for(var p=2;p<o;p++)i[p]=a[p];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}u.displayName="MDXCreateElement"},33946:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>m,frontMatter:()=>o,metadata:()=>l,toc:()=>p});var n=a(87462),r=(a(67294),a(3905));const o={id:"from-akka",title:"How to Migrate From Akka to ZIO?",sidebar_label:"Migration From Akka"},i=void 0,l={unversionedId:"guides/migrate/from-akka",id:"guides/migrate/from-akka",title:"How to Migrate From Akka to ZIO?",description:"Overview",source:"@site/docs/guides/migrate/from-akka.md",sourceDirName:"guides/migrate",slug:"/guides/migrate/from-akka",permalink:"/guides/migrate/from-akka",draft:!1,editUrl:"https://github.com/zio/zio/edit/series/2.x/docs/guides/migrate/from-akka.md",tags:[],version:"current",frontMatter:{id:"from-akka",title:"How to Migrate From Akka to ZIO?",sidebar_label:"Migration From Akka"},sidebar:"guides-sidebar",previous:{title:"ZIO 2.x Migration Guide",permalink:"/guides/migrate/zio-2.x-migration-guide"},next:{title:"Migration from Cats Effect",permalink:"/guides/migrate/from-cats-effect"}},s={},p=[{value:"Overview",id:"overview",level:2},{value:"Akka From the Perspective of a ZIO Developer",id:"akka-from-the-perspective-of-a-zio-developer",level:2},{value:"They Are Not Composable",id:"they-are-not-composable",level:3},{value:"When All We Have Is A Hammer",id:"when-all-we-have-is-a-hammer",level:3},{value:"Eager Evaluation",id:"eager-evaluation",level:3},{value:"Akka Actors And Futures",id:"akka-actors-and-futures",level:3},{value:"Akka Use-cases",id:"akka-use-cases",level:2},{value:"1. Parallelism",id:"1-parallelism",level:2},{value:"Parallelism in Akka",id:"parallelism-in-akka",level:3},{value:"Parallelism in ZIO",id:"parallelism-in-zio",level:3},{value:"2. Concurrent State Management",id:"2-concurrent-state-management",level:2},{value:"State Management in Akka",id:"state-management-in-akka",level:3},{value:"State Management in ZIO",id:"state-management-in-zio",level:3},{value:"3. Buffering Workloads",id:"3-buffering-workloads",level:2},{value:"Buffering Workloads in Akka",id:"buffering-workloads-in-akka",level:3},{value:"Buffering Workloads in ZIO",id:"buffering-workloads-in-zio",level:3},{value:"4. Streaming",id:"4-streaming",level:2},{value:"Streaming in Akka",id:"streaming-in-akka",level:3},{value:"Streaming in ZIO",id:"streaming-in-zio",level:3},{value:"5. HTTP Applications",id:"5-http-applications",level:2},{value:"HTTP Applications in Akka",id:"http-applications-in-akka",level:3},{value:"HTTP Applications in ZIO",id:"http-applications-in-zio",level:3},{value:"6. Event Sourcing",id:"6-event-sourcing",level:2},{value:"Event Sourcing in Akka",id:"event-sourcing-in-akka",level:3},{value:"Event Sourcing in ZIO",id:"event-sourcing-in-zio",level:3},{value:"7. Entity Sharding",id:"7-entity-sharding",level:2},{value:"Entity Sharding in Akka",id:"entity-sharding-in-akka",level:3},{value:"Entity Sharding in ZIO",id:"entity-sharding-in-zio",level:3},{value:"8. Distributed Computing",id:"8-distributed-computing",level:2}],c={toc:p},d="wrapper";function m(e){let{components:t,...a}=e;return(0,r.kt)(d,(0,n.Z)({},c,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"overview"},"Overview"),(0,r.kt)("p",null,"Here, we summarized alternative ZIO solutions for Akka Actor features. So before starting the migration, let's see an overview of corresponding features in ZIO:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Topics"),(0,r.kt)("th",{parentName:"tr",align:null},"Akka"),(0,r.kt)("th",{parentName:"tr",align:null},"ZIO"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Parallelism"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka/current/index.html"},"Akka Actor")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://zio.dev/reference/core/zio/"},"ZIO"),", ",(0,r.kt)("a",{parentName:"td",href:"https://zio.dev/reference/concurrency/"},"Concurrent Data Types"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Concurrent State Management"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka/current/index.html"},"Akka Actor")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/reference/state-management/global-shared-state"},"Ref"),", ",(0,r.kt)("a",{parentName:"td",href:"/reference/state-management/fiberref"},"FiberRef"),", ",(0,r.kt)("a",{parentName:"td",href:"/reference/state-management/zstate"},"ZState"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Buffering Workloads"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka/current/typed/mailboxes.html"},"Akka Mailboxes")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/reference/concurrency/queue"},"Queue"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Streaming"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka/current/stream/index.html"},"Akka Streams")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"../../reference/stream"},"ZIO Streams"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"HTTP Applications"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka-http/current/index.html"},"Akka Http")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://github.com/zio/zio-http"},"ZIO HTTP"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Event Sourcing"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://www.lagomframework.com/"},"Lagom Framework"),", ",(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka/current/persistence.html"},"Akka Persistence")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://github.com/thehonesttech/zio-entity"},"ZIO Entity"),", ",(0,r.kt)("a",{parentName:"td",href:"https://edomata.ir/"},"Edomata"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Entity Sharding"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka/current/typed/cluster-sharding.html"},"Akka Cluster Sharding")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://devsisters.github.io/shardcake/"},"Shardcake"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Scheduling"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka/2.5.32/scheduler.html"},"Akka Scheduler")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"../../reference/schedule"},"Schedule data type"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Cron-like Scheduling"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://github.com/enragedginger/akka-quartz-scheduler"},"Akka Quartz Scheduler")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"../../reference/schedule"},"Schedule data type"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Resiliency"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka/current/common/circuitbreaker.html"},"Akka CircuitBreaker")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"../../reference/schedule"},"Schedule data type"),", ",(0,r.kt)("a",{parentName:"td",href:"https://www.vroste.nl/rezilience/"},"Rezilience"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Logging"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka/current/logging.html"},"Built-in Support")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/guides/tutorials/enable-logging-in-a-zio-application"},"Built-in Support"),", ",(0,r.kt)("a",{parentName:"td",href:"/zio-logging/"},"ZIO Logging"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Testing"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka/current/typed/testing.html"},"Akka Testkit")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"../../reference/test"},"ZIO Test"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Testing Streams"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka/current/stream/stream-testkit.html"},"Akka Stream Testkit")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"../../reference/test"},"ZIO Test"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Metrics"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka/current/cluster-metrics.html"},"Cluster Metric Extension")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"../../reference/observability/metrics"},"Metrics"),", ",(0,r.kt)("a",{parentName:"td",href:"../../zio-metrics/index.md"},"ZIO Metrics"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Supervision"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka/current/general/supervision.html"},"Yes")),(0,r.kt)("td",{parentName:"tr",align:null},"Yes")),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Monitoring"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka/current/general/supervision.html"},"Yes")),(0,r.kt)("td",{parentName:"tr",align:null},"Yes")))),(0,r.kt)("p",null,"There are also several integration libraries for Akka that cover a wide range of technologies. If you use any of these technologies, you have a chance to use the equivalent of them in the ZIO ecosystem:"),(0,r.kt)("table",null,(0,r.kt)("thead",{parentName:"table"},(0,r.kt)("tr",{parentName:"thead"},(0,r.kt)("th",{parentName:"tr",align:null},"Tools"),(0,r.kt)("th",{parentName:"tr",align:null},"Alpakka"),(0,r.kt)("th",{parentName:"tr",align:null},"ZIO Connect"))),(0,r.kt)("tbody",{parentName:"table"},(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"gRPC"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka-grpc/current/index.html"},"Akka gRPC")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/ecosystem/community/zio-grpc"},"ZIO gRPC"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"GraphQL"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://github.com/sangria-graphql/sangria-akka-http-example"},"Sangria")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/ecosystem/community/caliban"},"Caliban"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Apache Kafka"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka-kafka/current/home.html"},"Alpakka Kafka")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/zio-kafka/"},"ZIO Kafka"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"AWS"),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/zio-aws/"},"ZIO AWS"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"AWS S3"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/s3.html"},"Alpakka S3")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://github.com/zio/zio-s3"},"ZIO S3"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"AWS SNS"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/sns.html"},"Alpakka SNS")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/zio-aws/"},"ZIO AWS SNS"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"AWS SQS"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/sqs.html"},"Alpakka SQS")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/zio-sqs/"},"ZIO SQS"),", ",(0,r.kt)("a",{parentName:"td",href:"/zio-aws/"},"ZIO AWS SQS"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"AMQP"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/amqp.html"},"Alpakka AMQP")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/ecosystem/community/zio-amqp"},"ZIO AMQP"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"AWS Kinesis"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/kinesis.html"},"Alpakka Kinesis")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/ecosystem/community/zio-kinesis"},"ZIO Kinesis"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"AWS DynamoDB"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/dynamodb.html"},"Alpakka DynamoDB")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://github.com/zio/zio-dynamodb"},"ZIO DynamoDB"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Pulsar"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/external/pulsar.html"},"Pulsar4s")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/ecosystem/community/zio-pulsar"},"ZIO Pulsar"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"AWS Lambda"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/awslambda.html"},"Alpakka AWS Lambda")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://github.com/zio/zio-lambda"},"ZIO Lambda"),", ",(0,r.kt)("a",{parentName:"td",href:"/zio-aws/"},"ZIO AWS Lambda"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/cassandra.html"},"Alpakka Cassandra")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://github.com/palanga/zio-cassandra"},"ZIO Cassandra"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Elasticsearch"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/elasticsearch.html"},"Alpakka Elasticsearch")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://github.com/aparo/zio-elasticsearch"},"ZIO Elasticsearch"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"FTP"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/ftp.html"},"Alpakka FTP")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/zio-ftp/"},"ZIO FTP"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://github.com/mbannour/zio-mongodb"},"ZIO MongoDB"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Redis"),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/zio-redis/"},"ZIO Redis"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Data Codecs"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/avroparquet.html"},"Alpakka Avro Parquet")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/zio-schema/"},"ZIO Schema"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null}),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/zio-nio/"},"ZIO NIO"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Slick"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/slick.html"},"Alpakka Slick")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/ecosystem/community/zio-slick-interop"},"ZIO Slick Interop"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Google Cloud Pub/Sub"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/google-cloud-pub-sub.html"},"Alpakka Google Cloud Pub/Sub")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://github.com/zio/zio-gcp"},"ZIO GCP Pub/Sub"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Google Cloud Storage"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/google-cloud-storage.html"},"Alpakka Google Cloud Storage")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://github.com/zio/zio-gcp"},"ZIO GCP Storage"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Json"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/data-transformations/json.html"},"Alpakka JSON Streaming")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/zio-json/"},"ZIO JSON"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"OrientDB"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/alpakka/current/orientdb.html"},"Alpakka OrientDB")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/zio-quill/"},"ZIO Quill OrientDB"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Logging"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka/current/typed/logging.html"},"Akka SL4J")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/zio-logging/"},"ZIO Logging SLF4J"))),(0,r.kt)("tr",{parentName:"tbody"},(0,r.kt)("td",{parentName:"tr",align:null},"Caching"),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"https://doc.akka.io/docs/akka-http/current/common/caching.html"},"Akka HTTP Caching")),(0,r.kt)("td",{parentName:"tr",align:null},(0,r.kt)("a",{parentName:"td",href:"/zio-cache/"},"ZIO Cache"))))),(0,r.kt)("p",null,"We also have several other libraries that may not be covered by the Akka ecosystem, but you can still use them. So we encourage you to check the ecosystem section of the ZIO website; take a look at the libraries, and see if they are suitable for your requirements for the migration process."),(0,r.kt)("h2",{id:"akka-from-the-perspective-of-a-zio-developer"},"Akka From the Perspective of a ZIO Developer"),(0,r.kt)("h3",{id:"they-are-not-composable"},"They Are Not Composable"),(0,r.kt)("p",null,"Akka actors are modeled as a partial function from ",(0,r.kt)("inlineCode",{parentName:"p"},"Any")," to ",(0,r.kt)("inlineCode",{parentName:"p"},"Unit"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"type Actor = PartialFunction[Any, Unit]\n")),(0,r.kt)("p",null,"In other words, an actor accepts something and does something with it. Both its input and output are not well typed. It is just like a blackbox. We know that having these types of functions is not composable. So it is hard to write small pieces of actors and compose them together to build large applications."),(0,r.kt)("p",null,"While in ZIO everything is composable. We can write composable computational abstractions and compose them together to build large applications. Due to the support for referential transparency, we can reason about small pieces of code and then make sure the whole application is correct."),(0,r.kt)("h3",{id:"when-all-we-have-is-a-hammer"},"When All We Have Is A Hammer"),(0,r.kt)("p",null,"The primary tool in object-oriented programming is object. Objects bundle the data and behavior. In OOP evertything is an object. So we have one tool to solve all problems."),(0,r.kt)("p",null,"Akka actors are the same. Each actor is an object which has its own state and behavior. Except that Akka actors are not synchronous. We can send messages to them asynchronously. This is where the Akka actors are different from the traditional objects. But the philosophy is the same: everything is an actor. So we have one tool to solve all problems."),(0,r.kt)("p",null,"But in reality, we don't need to use actors for everything. Many computations do not require any state. We just need to transform the input and produce the output. In ZIO We can use functions for them. Composing functions allows us to build large applications. Although if we need a state, we can use recursive functions or ",(0,r.kt)("inlineCode",{parentName:"p"},"Ref")," to model the state without losing referential transparency and composability."),(0,r.kt)("p",null,"Other than actors, there are many lightweight tools that can solve concurrency and parallelism problems:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"/reference/fiber/fiber.md"},"Fiber")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"/reference/concurrency/ref"},"Ref")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"/reference/concurrency/promise"},"Promise")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"/reference/concurrency/semaphore"},"Semaphore")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"/reference/concurrency/queue"},"Queue")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"/reference/concurrency/hub"},"Hub")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("a",{parentName:"li",href:"/reference/sync/"},"Synchronization Primitives"))),(0,r.kt)("p",null,"So it doesn't make sense to use actors for everything. It is better to choose the right tool for the right problem."),(0,r.kt)("h3",{id:"eager-evaluation"},"Eager Evaluation"),(0,r.kt)("p",null,"The primary evaluation strategy in ZIO is lazy evaluation. In other words, our code isn't evaluated until it's actually needed. So when we write ZIO applications, we are defining a description of the program. This enables us to model the program as a data structure. We can then transform the data structure to build a new program. So this makes us more productive by having reusable and composable abstractions."),(0,r.kt)("p",null,"So a ZIO application, is composed of series of ZIO values that are description of the whole workflow, finally when we provide the entire application to the ",(0,r.kt)("inlineCode",{parentName:"p"},"run")," method, the ZIO runtime will execute the application."),(0,r.kt)("p",null,"In contrast, in Akka, the primary evaluation strategy is eager evaluation, except for some part (e.g. Akka Typed). So when we writing Akka application, we are writing a sequence of instructions. This makes it hard to reuse and compose the pieces of code. We can't transform the instructions to build a new program."),(0,r.kt)("h3",{id:"akka-actors-and-futures"},"Akka Actors And Futures"),(0,r.kt)("p",null,"Akka actors are modeled on top of Scala ",(0,r.kt)("inlineCode",{parentName:"p"},"Future"),". Both ",(0,r.kt)("inlineCode",{parentName:"p"},"Future")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"Actor")," are asynchronous. Futures are mainly used in Akka by the ",(0,r.kt)("inlineCode",{parentName:"p"},"Ask")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"PipeTo")," methods."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"Future")," is a data structure that represents a value that may not yet be available. It models the asynchronous computation, but the most problem with ",(0,r.kt)("inlineCode",{parentName:"p"},"Future")," is that it is not referentially transparent. So even though we can compose ",(0,r.kt)("inlineCode",{parentName:"p"},"Future"),"s together, we can't reason about the whole program. As a result, we cannot ensure that the whole program is correct."),(0,r.kt)("p",null,"Furthermore, Futures are already running asynchronous constructs, so we cannot control their execution. For example, assume we have two ",(0,r.kt)("inlineCode",{parentName:"p"},"Future"),"s; we want to run them concurrently and return the first one that finishes. It is possible to do it with ",(0,r.kt)("inlineCode",{parentName:"p"},"Future"),", but we cannot cancel the already running loser ",(0,r.kt)("inlineCode",{parentName:"p"},"Future"),"."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"ZIO")," data type is an alternative construct for ",(0,r.kt)("inlineCode",{parentName:"p"},"Future"),". It is referentially transparent. We can compose ",(0,r.kt)("inlineCode",{parentName:"p"},"ZIO")," values together and reason about the whole program. So we can make sure the entire program is correct."),(0,r.kt)("p",null,"ZIO support a nice interruption mechanism. We can easily cancel any running ",(0,r.kt)("inlineCode",{parentName:"p"},"ZIO")," workflow using ",(0,r.kt)("inlineCode",{parentName:"p"},"Fiber#interrupt"),". Also, there are high-level APIs on top of interruption. For example, we have ",(0,r.kt)("inlineCode",{parentName:"p"},"race")," operators, where we can run multiple ZIO workflows and get the first successful result: ",(0,r.kt)("inlineCode",{parentName:"p"},'ZIO.succeed("Hello!").delay(1.second).race(ZIO.succeed("Hi!").delay(2.second))'),". ZIO automatically cancels the loser computation."),(0,r.kt)("h2",{id:"akka-use-cases"},"Akka Use-cases"),(0,r.kt)("p",null,"Before starting the migration, we need to understand what types of use-cases developers use Akka for."),(0,r.kt)("p",null,"Akka is a toolkit for building highly concurrent, distributed, and resilient message-driven applications. Here are the most common use-cases for Akka among developers:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"#1-parallelism"},"Parallelism")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"#2-concurrent-state-management"},"Concurrent State Management")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"#3-buffering-workloads"},"Buffering Workloads")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"#4-streaming"},"Streaming")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"#5-http-applications"},"HTTP Applications")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"#6-event-sourcing"},"Event Sourcing")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"#7-entity-sharding"},"Entity Sharding")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"#8-distributed-computing"},"Distributed Computing"))),(0,r.kt)("p",null,"Let's see an example of each use-case in a simple application using Akka."),(0,r.kt)("h2",{id:"1-parallelism"},"1. Parallelism"),(0,r.kt)("h3",{id:"parallelism-in-akka"},"Parallelism in Akka"),(0,r.kt)("p",null,"We can achieve parallelism in Akka by creating multiple instances of an actor and sending messages to them. Akka takes care of how to route messages to these actors. In the following example, we have a simple ",(0,r.kt)("inlineCode",{parentName:"p"},"JobRunner")," actor which accepts ",(0,r.kt)("inlineCode",{parentName:"p"},"Job")," messages and runs them one by one:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import akka.actor._\n\ncase class Job(n: Int)\n\nclass JobRunner extends Actor {\n  override def receive = { case Job(n) =>\n    println(s"job$n \u2014 started")\n    Thread.sleep(1000)\n    println(s"job$n \u2014 finished")\n  }\n}\n')),(0,r.kt)("p",null,"If we have plenty of jobs to run, we can create a pool of ",(0,r.kt)("inlineCode",{parentName:"p"},"JobRunner")," actors and send them jobs to make them run in parallel:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import akka.actor._\nimport akka.routing.RoundRobinPool\n\nobject MainApp extends scala.App {\n  val actorSystem = ActorSystem("parallel-app")\n  val jobRunner = actorSystem.actorOf(\n    Props[JobRunner].withRouter(RoundRobinPool(4)),\n    "job-runner"\n  )\n\n  for (job <- (1 to 10).map(Job)) {\n    jobRunner ! job\n  }\n}\n')),(0,r.kt)("h3",{id:"parallelism-in-zio"},"Parallelism in ZIO"),(0,r.kt)("p",null,"In ZIO we can achieve the same functionality easily by using ",(0,r.kt)("inlineCode",{parentName:"p"},"ZIO.foreachPar")," operators:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import zio._\n\nobject MainApp extends ZIOAppDefault {\n\n  def jobRunner(n: Int) =\n    for {\n      _ <- Console.printLine(s"job$n - started")\n      _ <- ZIO.sleep(1.second)\n      _ <- Console.printLine(s"job$n - finished")\n    } yield ()\n\n  val jobs = (1 to 10)\n  \n  def run = ZIO.foreachParDiscard(jobs)(jobRunner)\n}\n')),(0,r.kt)("p",null,"We use ",(0,r.kt)("inlineCode",{parentName:"p"},"ZIO.withParallelism")," operator to change the default parallelism factor:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"ZIO.withParallelism(4) {\n  ZIO.foreachParDiscard(jobs)(jobRunner)\n} \n")),(0,r.kt)("h2",{id:"2-concurrent-state-management"},"2. Concurrent State Management"),(0,r.kt)("h3",{id:"state-management-in-akka"},"State Management in Akka"),(0,r.kt)("p",null,"The main purpose of Akka actors is to write concurrent stateful applications. Using Akka actors, we can have stateful actors without worrying about concurrent access to the shared state. In the following example, we have a simple ",(0,r.kt)("inlineCode",{parentName:"p"},"Counter")," actor which accepts ",(0,r.kt)("inlineCode",{parentName:"p"},"inc")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"dec")," messages and increments or decrements its internal state:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import akka.actor.Actor\n\nclass Counter extends Actor {\n  private var state = 0\n\n  override def receive: Receive = {\n    case "inc" =>\n      state += 1\n    case "dec" =>\n      state -= 1\n    case "get" =>\n      sender() ! state\n  }\n}\n')),(0,r.kt)("p",null,"Now we can create an instance of the ",(0,r.kt)("inlineCode",{parentName:"p"},"Counter")," actor and send it ",(0,r.kt)("inlineCode",{parentName:"p"},"inc")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"dec")," messages to increment and decrement its internal state:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import akka.actor.{ActorSystem, Props}\nimport akka.pattern.ask\nimport akka.util.Timeout\nimport scala.concurrent.duration.DurationInt\nimport scala.concurrent.{ExecutionContext, ExecutionContextExecutor}\nimport scala.util.{Failure, Success}\n\nobject MainApp extends App {\n  val system = ActorSystem("counter-app")\n  val counterActor = system.actorOf(Props[Counter], "counter")\n\n  implicit val ec: ExecutionContextExecutor = ExecutionContext.global\n  implicit val timeout: Timeout = Timeout(1.second)\n\n  counterActor ! "inc"\n  counterActor ! "inc"\n  counterActor ! "inc"\n  counterActor ! "dec"\n\n  (counterActor ? "get").onComplete {\n    case Success(v) =>\n      println(s"The current value of counter: $v")\n    case Failure(e) =>\n      println(s"Failed to receive the result from the counter: ${e.getMessage}")\n  }\n\n}\n')),(0,r.kt)("p",null,"Outside the actor, we haven't access to its internal states, so we can't modify it directly. We can only send messages to the actor and let it handle the state management on its own. Using this approach, we can have safe concurrent state management. If multiple actors send messages to this actor concurrently, they can't make the state inconsistent."),(0,r.kt)("h3",{id:"state-management-in-zio"},"State Management in ZIO"),(0,r.kt)("p",null,"State management is very easy in ZIO in presence of the ",(0,r.kt)("inlineCode",{parentName:"p"},"Ref")," data type. ",(0,r.kt)("inlineCode",{parentName:"p"},"Ref")," models a mutable state which is safe for concurrent access:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"import zio._\n\ncase class Counter(state: Ref[Int]) {\n  def inc = state.update(_ + 1)\n  def dec = state.update(_ - 1)\n  def get = state.get\n}\n\nobject Counter {\n  def make = Ref.make(0).map(Counter(_))\n}\n")),(0,r.kt)("p",null,"That's it! Very simple! We now we can use the counter in a program:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import zio._\n\nobject MainApp extends ZIOAppDefault {\n  def run =\n    for {\n      c <- Counter.make\n      _ <- c.inc <&> c.inc <&> c.inc <&> c.dec\n      _ <- c.get.debug("The current value of the counter")\n    } yield ()\n}\n')),(0,r.kt)("h2",{id:"3-buffering-workloads"},"3. Buffering Workloads"),(0,r.kt)("p",null,"Sometimes we have to deal with a high volume of incoming requests. In spite of parallelism and concurrency, we may not be able to handle all incoming requests within a short period of time. In such cases, we can use a buffer to store incoming requests temporarily and process them later."),(0,r.kt)("h3",{id:"buffering-workloads-in-akka"},"Buffering Workloads in Akka"),(0,r.kt)("p",null,"Each actor in Akka has a mailbox that is used to store incoming messages. The mailbox is a FIFO queue. Actors only process one message at a time. If an actor receives more messages than it can process, the messages will be pending in the mailbox:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import akka.actor.{Actor, ActorSystem, Props}\n\nimport scala.concurrent.Await\nimport scala.concurrent.duration.Duration\n\nobject MainApp extends scala.App {\n  val actorSystem = ActorSystem("parallel-app")\n  val worker = actorSystem.actorOf(Props[JobRunner], "worker")\n\n  val jobs = (1 to 1000).map(Job)\n\n  for (job <- jobs) {\n    worker ! job\n  }\n\n  println("All messages were sent to the actor!")\n\n  Await.result(actorSystem.whenTerminated, Duration.Inf)\n}\n')),(0,r.kt)("p",null,"If we run the above example, we can see that all messages are sent to the actor before, and the actor still processing messages from the mailbox one by one. By default, the mailbox is an unbounded FIFO queue. But we can also use a bounded mailbox or a custom priority mailbox."),(0,r.kt)("h3",{id:"buffering-workloads-in-zio"},"Buffering Workloads in ZIO"),(0,r.kt)("p",null,"ZIO has a data type called ",(0,r.kt)("inlineCode",{parentName:"p"},"Queue")," which is useful for buffering workloads:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"import zio._\nimport zio.stream._\n\ntrait Actor[-In] {\n  def tell(i: In): UIO[Boolean]\n}\n\nobject Actor {\n  def make[In](receive: In => UIO[Unit]): ZIO[Scope, Nothing, Actor[In]] =\n    for {\n      queue <- Queue.unbounded[In]\n      _     <- queue.take.flatMap(receive).forever.forkScoped\n    } yield new Actor[In] {\n      override def tell(i: In): UIO[Boolean] =\n        queue.offer(i)\n    }\n}\n")),(0,r.kt)("p",null,"Now we can send a high load of messages to the actor and the actor will process them one by one:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import zio._\n\nobject MainApp extends ZIOAppDefault {\n  def run = ZIO.scoped {\n    for {\n      actor <- Actor.make[Int](n => ZIO.debug(s"processing job-$n").delay(1.second))\n      _     <- ZIO.foreachParDiscard(1 to 1000)(actor.tell)\n      _     <- ZIO.debug("All messages were sent to the actor!")\n      _     <- ZIO.never\n    } yield ()\n  }\n}\n')),(0,r.kt)("h2",{id:"4-streaming"},"4. Streaming"),(0,r.kt)("h3",{id:"streaming-in-akka"},"Streaming in Akka"),(0,r.kt)("p",null,"Akka stream is developed on top of Akka actors with backpressure support. There are three main components in Akka streams:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},"Source"),(0,r.kt)("li",{parentName:"ol"},"Sink"),(0,r.kt)("li",{parentName:"ol"},"Flow")),(0,r.kt)("p",null,"Here is a simple example of how to have a streaming app in Akka:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import akka.actor.ActorSystem\nimport akka.stream.scaladsl._\nimport akka.util.ByteString\n\nimport java.nio.file.Paths\nimport scala.concurrent._\n\nobject AkkaStreamApp extends App {\n  implicit val system: ActorSystem = ActorSystem("stream")\n  implicit val ec: ExecutionContextExecutor = system.dispatcher\n\n  val source = Source(1 to 100)\n  val factorial = Flow[Int].scan(BigInt(1))((acc, next) => acc * next)\n  val serialize = Flow[BigInt].map(num => ByteString(s"$num\\n"))\n  val sink = FileIO.toPath(Paths.get("factorials.txt"))\n\n  source\n    .via(factorial)\n    .via(serialize)\n    .runWith(sink)\n    .onComplete(_ => system.terminate())\n}\n')),(0,r.kt)("h3",{id:"streaming-in-zio"},"Streaming in ZIO"),(0,r.kt)("p",null,"ZIO Streams is a purely functional, composable, effectful, and resourceful streaming library. It provides a way to model streaming data processing as a pure function. It is built on top of ZIO and supports backpressure using a pull-based model."),(0,r.kt)("p",null,"Like the Akka terminology, ZIO streams have three main components:"),(0,r.kt)("ol",null,(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"/reference/stream/zstream/"},"ZStream")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"/reference/stream/zpipeline"},"ZPipeline")),(0,r.kt)("li",{parentName:"ol"},(0,r.kt)("a",{parentName:"li",href:"/reference/stream/zsink/"},"ZSink"))),(0,r.kt)("p",null,"Let's see how to implement the same example in ZIO:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import zio._\nimport zio.stream._\n\nobject ZIOStreamApp extends ZIOAppDefault {\n  val source    = ZStream.fromIterable(1 to 100)\n  val factorial = ZPipeline.scan(BigInt(1))((acc, next: Int) => acc * next)\n  val serialize = ZPipeline.map((num: BigInt) => Chunk.fromArray(s"$num".getBytes))\n  val sink      = ZSink.fromFileName("factorials.txt")\n\n  def run = \n    source\n      .via(factorial)\n      .via(serialize).flattenChunks\n      .run(sink)\n}\n')),(0,r.kt)("h2",{id:"5-http-applications"},"5. HTTP Applications"),(0,r.kt)("h3",{id:"http-applications-in-akka"},"HTTP Applications in Akka"),(0,r.kt)("p",null,"Akka HTTP is a library for building HTTP applications on top of Akka actors and streams. It supports both server-side and client-side HTTP applications:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import akka.actor.typed.ActorSystem\nimport akka.actor.typed.scaladsl.Behaviors\nimport akka.http.scaladsl.Http\nimport akka.http.scaladsl.model._\nimport akka.http.scaladsl.server.Directives._\n\nobject AkkHttpServer extends App {\n  implicit val system = ActorSystem(Behaviors.empty, "system")\n  implicit val executionContext = system.executionContext\n\n  Http().newServerAt("localhost", 8080).bind {\n    path("hello") {\n      get {\n        complete(\n          HttpEntity(\n            ContentTypes.`text/html(UTF-8)`,\n            "<h1>Say hello to akka-http</h1>"\n          )\n        )\n      }\n    }\n  }\n}\n')),(0,r.kt)("h3",{id:"http-applications-in-zio"},"HTTP Applications in ZIO"),(0,r.kt)("p",null,"On the other hand, ZIO has a library called ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/zio/zio-http"},"ZIO HTTP")," which is a pure functional library for building HTTP applications. It is on top of ZIO, ZIO Streams."),(0,r.kt)("p",null,"Let's see how the above Akka HTTP service can be written in ZIO:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import zhttp.html.Html\nimport zhttp.http._\nimport zhttp.service.Server\nimport zio.ZIOAppDefault\n\nobject ZIOHttpServer extends ZIOAppDefault {\n  def run = Server.start(\n    port = 8080,\n    http = Http.collect[Request] { case Method.GET -> !! / "hello" =>\n      Response.html(Html.fromString("<h1>Say hello to zio-http</h1>"))\n    }\n  )\n}\n')),(0,r.kt)("h2",{id:"6-event-sourcing"},"6. Event Sourcing"),(0,r.kt)("h3",{id:"event-sourcing-in-akka"},"Event Sourcing in Akka"),(0,r.kt)("p",null,"In event sourcing, we store the events that happened in the past and use them to reconstruct the current state of the application. Akka has a built-in solution called Akka Persistence."),(0,r.kt)("p",null,"In the following example, we have a simple ",(0,r.kt)("inlineCode",{parentName:"p"},"PersistentCounter")," actor which accepts ",(0,r.kt)("inlineCode",{parentName:"p"},"inc")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"dec")," messages and increments or decrements in its internal state and also sores incoming events in persistent storage. When the actor is restarted, it will recover its state from the persistent storage:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import akka.actor.{ActorSystem, Props}\nimport akka.pattern.ask\nimport akka.persistence._\nimport akka.util.Timeout\n\nimport scala.concurrent.duration.DurationInt\nimport scala.concurrent.{ExecutionContext, ExecutionContextExecutor}\nimport scala.util.{Failure, Success}\n\nclass PersistentCounter extends PersistentActor {\n  private var state: Int = 0\n\n  override def receive = {\n    case "inc" => persist("inc")(_ => state += 1)\n    case "dec" => persist("dec")(_ => state -= 1)\n    case "get" => sender() ! state\n  }\n\n  override def receiveRecover = {\n    case "inc" => state += 1\n    case "dec" => state -= 1\n  }\n\n  override def receiveCommand: Receive = _ => ()\n\n  override def persistenceId: String = "my-persistence-id"\n}\n\nobject MainApp extends App {\n  val system = ActorSystem("counter-app")\n  val counter = system.actorOf(Props[PersistentCounter], "counter")\n\n  implicit val ec: ExecutionContextExecutor = ExecutionContext.global\n  implicit val timeout: Timeout = Timeout(1.second)\n\n  counter ! "inc"\n  counter ! "inc"\n  counter ! "inc"\n  counter ! "dec"\n\n  (counter ? "get").onComplete {\n    case Success(v) =>\n      println(s"Current value of the counter: $v")\n    case Failure(e) =>\n      println(s"Failed to receive the result from the counter: ${e.getMessage}")\n  }\n\n}\n')),(0,r.kt)("h3",{id:"event-sourcing-in-zio"},"Event Sourcing in ZIO"),(0,r.kt)("p",null,"In the ZIO ecosystem, we have a community library called ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/thehonesttech/zio-entity"},"ZIO Entity")," which aims to provide a distributed event-sourcing solution. Although it is not production-ready yet, there is nothing to worry about. We can write our toolbox or use other libraries from other functional effect ecosystems using ZIO Interop."),(0,r.kt)("p",null,"Note that based on your use case, you may don't need any event-sourcing framework or library. So before using any library, you should consider if you really need it or not. In many cases, this is very dependent on our domain and business requirements, and using a library may mislead you in the wrong direction."),(0,r.kt)("p",null,"Anyway, there is a purely functional library called ",(0,r.kt)("a",{parentName:"p",href:"https://edomata.ir/"},"Edomata")," which provides a simple solution for event sourcing. It is written in a tagless final style using ",(0,r.kt)("a",{parentName:"p",href:"https://typelevel.org/cats-effect/"},"Cats Effect")," and ",(0,r.kt)("a",{parentName:"p",href:"https://fs2.io/"},"Fs2"),". We can use ZIO Interop to use the ZIO effect to run an Edomaton."),(0,r.kt)("p",null,"In the following example, we are going to use Edomata to implement a simple counter which is event sourced. To do so, we need to define Events, Commands, State, Rejections, and Transitions:"),(0,r.kt)("p",null,"After finding out domain events, we can define them using enum or sealed traits. In this example, we have two ",(0,r.kt)("inlineCode",{parentName:"p"},"Increased")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"Decreased")," events:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"enum Event {\n  case Increased, Decreased\n}\n")),(0,r.kt)("p",null,"Then we should define the commands our domain can handle:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"enum Command {\n  case Inc, Dec\n}\n")),(0,r.kt)("p",null,"To notify some information data to the outside world, we can use ",(0,r.kt)("inlineCode",{parentName:"p"},"Notification"),"s, let's define a simple notification data type:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"case class Notification(message: String)\n")),(0,r.kt)("p",null,"Now it's time to define the domain model and the state of the counter:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import cats.data.ValidatedNec\nimport edomata.core.{Decision, DomainModel}\nimport cats.implicits.*\nimport edomata.syntax.all.*\n\ncase class Counter(state: Int) {\n  def inc = this.perform { Decision.accept(Event.Increased) }\n  def dec = this.perform {\n    if (state > 0) Decision.accept(Event.Decreased) else "decision rejected".reject\n  }\n}\n\nobject Counter extends DomainModel[Counter, Event, String] {\n  override def initial: Counter = Counter(0)\n\n  override def transition = {\n    case Event.Increased => state => state.copy(state = state.state + 1).validNec\n    case Event.Decreased => state => state.copy(state = state.state - 1).validNec\n  }\n}\n')),(0,r.kt)("p",null,"We are ready to define the ",(0,r.kt)("inlineCode",{parentName:"p"},"CounterService"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'object CounterService extends Counter.Service[Command, Notification] {\n  import App._\n  def apply(): PureApp[Unit] = router {\n    case Command.Inc =>\n      for {\n        counter <- state.decide(_.inc)\n        _ <- publish(Notification(s"state is going to become ${counter.state}"))\n      } yield ()\n    case Command.Dec => state.decide(_.dec).void\n  }\n}\n')),(0,r.kt)("p",null,"So far, we have defined an edomaton called ",(0,r.kt)("inlineCode",{parentName:"p"},"CounterService"),". To run it, we need a backend:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import scala.concurrent.duration.*\nimport cats.effect.std.Console\nimport cats.effect.{Async, Concurrent, Resource}\nimport cats.data.EitherNec\nimport edomata.core.{CommandMessage, DomainService}\nimport edomata.skunk.{BackendCodec, CirceCodec, SkunkBackend}\nimport edomata.backend.Backend\nimport edomata.skunk.SkunkBackend.PartialBuilder\nimport edomata.syntax.all.liftTo\nimport fs2.io.net.Network\nimport skunk.Session\nimport io.circe.generic.auto.*\nimport natchez.Trace\nimport natchez.Trace.Implicits.noop\nimport zio.*\nimport zio.interop.catz.*\n\nobject BackendService {\n  given BackendCodec[Event] = CirceCodec.jsonb // or .json\n  given BackendCodec[Notification] = CirceCodec.jsonb\n  given BackendCodec[Counter] = CirceCodec.jsonb\n  given Network[Task] = Network.forAsync[Task]\n  given Trace[Task] = Trace.Implicits.noop\n  given Console[Task] = Console.make[Task]\n\n  def backend =\n    SkunkBackend(\n      Session\n        .single("localhost", 5432, "postgres", "postgres", Some("postgres"))\n    )\n\n  def buildBackend =\n    backend\n      .builder(CounterService, "counter")\n      .withRetryConfig(retryInitialDelay = 2.seconds)\n      .persistedSnapshot(200)\n      .build\n      .toScopedZIO\n\n  type Service = CommandMessage[Command] => RIO[Scope, EitherNec[String, Unit]]\n\n  def service: ZIO[Scope, Throwable, Service] =\n    buildBackend\n      .map(_.compile(CounterService().liftTo[Task]))\n}\n')),(0,r.kt)("p",null,"To demonstrate how the backend works, we can write a simple web service that accepts ",(0,r.kt)("inlineCode",{parentName:"p"},"Inc")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"Dec")," commands:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import zio.*\nimport zhttp.http.*\nimport edomata.core.CommandMessage\nimport BackendService.Service\nimport java.time.Instant\n\nobject ZIOCounterHttpApp {\n\n  def apply(service: Service) =\n    Http.collectZIO[Request] {\n      // command: inc or dec\n      // GET /{edomaton address}/{command}/{command id}\n      case Method.GET -> !! / address / command / commandId =>\n        val cmd = command match {\n          case "inc" => Command.Inc\n          case "dec" => Command.Dec\n        }\n\n        service(CommandMessage(commandId, Instant.now, address, cmd))\n          .map(r => Response.text(r.toString))\n          .orDie\n    }\n}\n')),(0,r.kt)("p",null,"Now we can wire everything and run the application:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"import zio.*\nimport zio.interop.catz.*\nimport zhttp.http.*\nimport zhttp.service.Server\nimport cats.effect.std.Console\n\nobject MainApp extends ZIOAppDefault {\n  given Console[Task] = Console.make[Task]\n\n  def run =\n    ZIO.scoped {\n      for {\n        backendService <- BackendService.service\n        _ <- Server.start(8090, ZIOCounterHttpApp(backendService))\n      } yield ()\n    }\n}\n")),(0,r.kt)("p",null,"To test the application, we can send the following requests:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-http"},"GET /FooCounter/inc/cf2209c9-6b41-44da-8c52-7e0dce109dc3\nGET /FooCounter/inc/11aa920d-254e-4aa7-86f2-8002df80533b\nGET /FooCounter/dec/b2e8a02c-77db-463d-8213-d462fc5a9439\nGET /FooCounter/inc/9ac51e44-36d0-4daa-ac23-28e624bec174\n")),(0,r.kt)("p",null,"If multiple commands with the same command id are sent, the backend only processes the first one and ignores the rest. If the command is rejected, the backend will not accept any subsequent commands."),(0,r.kt)("p",null,"To see all the events or the current state associated with the ",(0,r.kt)("inlineCode",{parentName:"p"},"FooCounter")," adomaton, we can use the ",(0,r.kt)("inlineCode",{parentName:"p"},"Backend#repository")," to query the database:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import zio.*\nimport zio.interop.catz.*\nimport zio.stream.interop.fs2z._\nimport cats.effect.std.Console\n\nobject ZIOStateAndHistory extends ZIOAppDefault {\n  given Console[Task] = Console.make[Task]\n\n  def run =\n    ZIO.scoped {\n      for {\n        backendService <- BackendService.buildBackend.orDie\n        history <- backendService.repository\n          .history("FooCounter")\n          .toZStream()\n          .runCollect\n        state <- backendService.repository.get("FooCounter")\n        _ <- ZIO.debug(s"FooCounter History: $history")\n        _ <- ZIO.debug(s"FooCounter State: $state")\n      } yield ()\n    }\n}\n\n// Output:\n// FooCounter History: Chunk(Valid(Counter(0),0),Valid(Counter(1),1),Valid(Counter(2),2),Valid(Counter(1),3),Valid(Counter(2),4))\n// FooCounter State: Valid(Counter(2),4)\n')),(0,r.kt)("p",null,"That's it! By using functional programming instead of Akka actors, we implemented a simple event sourced counter."),(0,r.kt)("h2",{id:"7-entity-sharding"},"7. Entity Sharding"),(0,r.kt)("p",null,"Entity sharding is a technique for distributing a large number of entities across a cluster of nodes. It reduces resource contention by sharding the entities across the nodes. It also provides a way to scale out the system by adding more nodes to the system."),(0,r.kt)("h3",{id:"entity-sharding-in-akka"},"Entity Sharding in Akka"),(0,r.kt)("p",null,"Akka has a module called Akka Cluster Sharding that provides a way to distribute entities. Without further ado, in the following example, we are going to shard instances of the ",(0,r.kt)("inlineCode",{parentName:"p"},"Counter")," entity type and then create a web service that can be used to increment or decrement each entity."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import akka.actor.typed.scaladsl.Behaviors\nimport akka.actor.typed.{ActorRef, Behavior}\n\nobject Counter {\n  sealed trait Message\n  case class Increase(replyTo: ActorRef[Int]) extends Message\n  case class Decrease(replyTo: ActorRef[Int]) extends Message\n\n  def apply(entityId: String): Behavior[Message] = {\n    def updated(value: Int): Behavior[Message] = {\n      Behaviors.receive { (context, command) =>\n        val log = context.log\n        val address = context.system.address\n        command match {\n          case Increase(replyTo) =>\n            log.info(s"executing inc msg for $entityId entity inside $address")\n            val state = value + 1\n            replyTo ! state\n            updated(state)\n          case Decrease(replyTo) =>\n            log.info(s"executing dec msg for $entityId entity inside $address")\n            val state = value - 1\n            replyTo ! state\n            updated(state)\n        }\n      }\n    }\n    updated(0)\n  }\n}\n')),(0,r.kt)("p",null,"Now, it's time to create a simple web service that can be used to receive the ",(0,r.kt)("inlineCode",{parentName:"p"},"inc")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"dec")," commands from clients:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import akka.actor.typed.ActorSystem\n\nimport scala.concurrent.duration.DurationInt\nimport akka.actor.typed.scaladsl.AskPattern._\nimport akka.http.scaladsl.server.Directives._\nimport akka.http.scaladsl.server.Route\nimport akka.cluster.sharding.typed.ShardingEnvelope\nimport akka.util.Timeout\n\nobject CounterHttpApp {\n  implicit val timeout: Timeout = 1.seconds\n\n  def routes(implicit\n      system: ActorSystem[ShardingEnvelope[Counter.Message]]\n  ): Route = {\n    path(Segment / Segment) { case (entityId, command) =>\n      get {\n        val response = system.ask[Int](askReplyTo =>\n          ShardingEnvelope(\n            entityId,\n            command match {\n              case "inc" => Counter.Increase(askReplyTo)\n              case "dec" => Counter.Decrease(askReplyTo)\n            }\n          )\n        )\n        onComplete(response) { value =>\n          complete(value.toString)\n        }\n      }\n    }\n  }\n}\n')),(0,r.kt)("p",null,"To be able to shard instances of the ",(0,r.kt)("inlineCode",{parentName:"p"},"Counter")," entity, let's define the guardian behavior:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import akka.actor.typed.Behavior\nimport akka.actor.typed.scaladsl.Behaviors\nimport akka.cluster.sharding.typed.ShardingEnvelope\nimport akka.cluster.sharding.typed.scaladsl._\n\nobject Guardian {\n  def apply(): Behavior[ShardingEnvelope[Counter.Message]] =\n    Behaviors.setup { context =>\n      val TypeKey: EntityTypeKey[Counter.Message] =\n        EntityTypeKey[Counter.Message]("counter")\n      val clusterSharding = ClusterSharding(context.system)\n      val shardRegion =\n        clusterSharding.init(Entity(TypeKey)(c => Counter(c.entityId)))\n      Behaviors.receiveMessage { msg =>\n        shardRegion ! msg\n        Behaviors.same\n      }\n    }\n}\n')),(0,r.kt)("p",null,"To be able to run multiple instances of the application, we need to define a seed node and also let the application read the port number from the environment. So, let's create the ",(0,r.kt)("inlineCode",{parentName:"p"},"application.conf")," file in the ",(0,r.kt)("inlineCode",{parentName:"p"},"src/main/resources")," directory:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-hocon"},'akka {\n  actor {\n    allow-java-serial ization =true \n    provider = "cluster"\n  }\n  remote.artery.canonical {\n    hostname = "127.0.0.1" \n    port = 2551\n    port=${?PORT}\n  }\n  cluster.seed-nodes= ["akka://system@127.0.0.1:2551"]\n}\n\nwebservice {\n  host = "127.0.0.1"\n  port = 8082\n  port = ${?HTTP_PORT}\n}\n')),(0,r.kt)("p",null,"The final step is to wire everything together to create the application:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import akka.actor.typed.ActorSystem\nimport akka.cluster.sharding.typed.ShardingEnvelope\nimport akka.http.scaladsl.Http\nimport com.typesafe.config.ConfigFactory\n\nobject AkkaClusterShardingExample extends App {\n  val config = ConfigFactory.load("application.conf")\n\n  implicit val system: ActorSystem[ShardingEnvelope[Counter.Message]] =\n    ActorSystem(Guardian(), "system", config)\n\n  Http()\n    .newServerAt(\n      config.getString("webservice.host"),\n      config.getInt("webservice.port")\n    )\n    .bind(CounterHttpApp.routes)\n}\n')),(0,r.kt)("p",null,"To run the application, we need to start the seed node first:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'sbt -DHTTP_PORT=8081 -DPORT=2551 "runMain AkkaClusterShardingExample"\n')),(0,r.kt)("p",null,"Then, we can start some more nodes:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'sbt -DHTTP_PORT=8082 -DPORT=2552 "runMain AkkaClusterShardingExample"\nsbt -DHTTP_PORT=8083 -DPORT=2553 "runMain AkkaClusterShardingExample"\n')),(0,r.kt)("p",null,"Now, we can send some requests to any of theses nodes:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"GET http://localhost:8081/foo/inc\nGET http://localhost:8082/foo/inc\nGET http://localhost:8083/foo/inc\n\nGET http://localhost:8081/bar/inc\nGET http://localhost:8082/bar/inc\nGET http://localhost:8083/bar/inc\n\n// ...\n")),(0,r.kt)("p",null,"We can see that the each of ",(0,r.kt)("inlineCode",{parentName:"p"},"foo")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"bar")," entities will be executed in a single node at a time, even if we are sending requests to different nodes."),(0,r.kt)("h3",{id:"entity-sharding-in-zio"},"Entity Sharding in ZIO"),(0,r.kt)("p",null,"In the ZIO community, there is a library called ",(0,r.kt)("a",{parentName:"p",href:"https://devsisters.github.io/shardcake/"},"Shardcake")," that provides a purely functional API for entity sharding. It is highly configurable and customizable. Let's try to implement the same example as in the previous section using Shardcake."),(0,r.kt)("p",null,"First, we are going to define the ",(0,r.kt)("inlineCode",{parentName:"p"},"Counter")," entity:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.devsisters.shardcake.Messenger.Replier\nimport com.devsisters.shardcake._\nimport zio._\n\nsealed trait CounterMessage\nobject CounterMessage {\n  case class Increase(replier: Replier[Int]) extends CounterMessage\n  case class Decrease(replier: Replier[Int]) extends CounterMessage\n}\n\nobject Counter extends EntityType[CounterMessage]("counter") {\n\n  def handleMessage(\n    entityId: String,\n    state: Ref[Int],\n    message: CounterMessage\n  ): ZIO[Sharding, Nothing, Unit] =\n    podPort.flatMap { port =>\n      message match {\n        case CounterMessage.Increase(replier) =>\n          state\n            .updateAndGet(_ + 1)\n            .debug(s"The $entityId counter increased inside localhost:$port pod")\n            .flatMap(replier.reply)\n        case CounterMessage.Decrease(replier) =>\n          state\n            .updateAndGet(_ - 1)\n            .debug(s"The $entityId counter decreased inside localhost:$port pod")\n            .flatMap(replier.reply)\n      }\n    }\n\n  def behavior(\n    entityId: String,\n    messages: Dequeue[CounterMessage]\n  ): ZIO[Sharding, Nothing, Nothing] =\n    Ref.make(0).flatMap { state =>\n      messages.take.flatMap(handleMessage(entityId, state, _)).forever\n    }\n\n  def podPort: UIO[String] =\n    System\n      .env("PORT")\n      .some\n      .orDieWith(_ => new Exception("Application started without any specified port!"))\n}\n')),(0,r.kt)("p",null,"To be able to receive messages from the clients, let's define a web service:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.devsisters.shardcake.{ Messenger, Sharding }\nimport zhttp.http._\nimport zio.Scope\n\nobject WebService {\n  def apply(\n    counter: Messenger[CounterMessage]\n  ): Http[Sharding with Scope, Throwable, Request, Response] =\n    Http.collectZIO[Request] {\n      case Method.GET -> !! / entityId / "inc" =>\n        counter\n          .send(entityId)(CounterMessage.Increase)\n          .map(r => Response.text(r.toString))\n\n      case Method.GET -> !! / entityId / "dec" =>\n        counter\n          .send(entityId)(CounterMessage.Decrease)\n          .map(r => Response.text(r.toString))\n    }\n}\n')),(0,r.kt)("p",null,"In this example, we are going to use Redis as the storage backend for the sharding. So, let's define a live layer for the sharding:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.devsisters.shardcake.StorageRedis.Redis\nimport dev.profunktor.redis4cats.Redis\nimport dev.profunktor.redis4cats.connection.RedisClient\nimport dev.profunktor.redis4cats.data.RedisCodec\nimport dev.profunktor.redis4cats.effect.Log\nimport dev.profunktor.redis4cats.pubsub.PubSub\nimport zio.interop.catz._\nimport zio._\n\nobject RedisLive {\n  val layer: ZLayer[Any, Throwable, Redis] =\n    ZLayer.scopedEnvironment {\n      implicit val runtime: zio.Runtime[Any] = zio.Runtime.default\n      \n      implicit val logger: Log[Task] = new Log[Task] {\n        override def debug(msg: => String): Task[Unit] = ZIO.logDebug(msg)\n        override def error(msg: => String): Task[Unit] = ZIO.logError(msg)\n        override def info(msg: => String): Task[Unit]  = ZIO.logInfo(msg)\n      }\n\n      (for {\n        client   <- RedisClient[Task].from("redis://localhost")\n        commands <- Redis[Task].fromClient(client, RedisCodec.Utf8)\n        pubSub   <- PubSub.mkPubSubConnection[Task, String, String](client, RedisCodec.Utf8)\n      } yield ZEnvironment(commands, pubSub)).toScopedZIO\n    }\n}\n')),(0,r.kt)("p",null,"We also need a configuration layer for the sharding:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import zio._\nimport com.devsisters.shardcake.Config\n\nobject ShardConfig {\n  val layer: ZLayer[Any, SecurityException, Config] =\n    ZLayer(\n      System\n        .env("PORT")\n        .map(\n          _.flatMap(_.toIntOption)\n            .fold(Config.default)(port => Config.default.copy(shardingPort = port))\n        )\n    )\n}\n')),(0,r.kt)("p",null,"Now we are ready to create our application:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import com.devsisters.shardcake._\nimport zio._\nimport zhttp.service.Server\n\nobject HttpApp extends ZIOAppDefault {\n\n  def run: Task[Unit] =\n    ZIO.scoped {\n      for {\n        port    <- System.env("HTTP_PORT").map(_.flatMap(_.toIntOption).getOrElse(8080))\n        _       <- Sharding.registerEntity(Counter, Counter.behavior)\n        _       <- Sharding.registerScoped\n        counter <- Sharding.messenger(Counter)\n        _       <- Server.start(port, WebService(counter))\n      } yield ()\n    }.provide(\n      ShardConfig.layer,\n      ZLayer.succeed(GrpcConfig.default),\n      ZLayer.succeed(RedisConfig.default),\n      RedisLive.layer,\n      StorageRedis.live,\n      KryoSerialization.live,\n      ShardManagerClient.liveWithSttp,\n      GrpcPods.live,\n      Sharding.live,\n      GrpcShardingService.live\n    )\n}\n')),(0,r.kt)("p",null,"To manage sharding, we should run a separate application which is called ",(0,r.kt)("inlineCode",{parentName:"p"},"ShardManager"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"import zio._\nimport com.devsisters.shardcake.interfaces._\n\nobject ShardManagerApp extends ZIOAppDefault {\n  def run: Task[Nothing] =\n     com.devsisters.shardcake.Server.run.provide(\n      ZLayer.succeed(ManagerConfig.default),\n      ZLayer.succeed(GrpcConfig.default),\n      ZLayer.succeed(RedisConfig.default),\n      RedisLive.layer,\n      StorageRedis.live, // store data in Redis\n      PodsHealth.local,  // just ping a pod to see if it's alive\n      GrpcPods.live,     // use gRPC protocol\n      ShardManager.live  // Shard Manager logic\n    )\n}\n")),(0,r.kt)("p",null,"That's it! Now it's time to run the application. First, let's run an instance of Redis using docker:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"docker run -d -p 6379:6379 --name sampleredis redis\n")),(0,r.kt)("p",null,"Then, we can run the ",(0,r.kt)("inlineCode",{parentName:"p"},"ShardManager")," application:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},'sbt "runMain ShardManagerApp"\n')),(0,r.kt)("p",null,"Now, we can run multiple instances of ",(0,r.kt)("inlineCode",{parentName:"p"},"HttpApp"),":"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},'sbt -DHTTP_PORT=8081 -DPORT=8091 "runMain HttpApp"\nsbt -DHTTP_PORT=8082 -DPORT=8092 "runMain HttpApp"\nsbt -DHTTP_PORT=8083 -DPORT=8093 "runMain HttpApp"\n')),(0,r.kt)("p",null,"Finally, we can send requests to the ",(0,r.kt)("inlineCode",{parentName:"p"},"HttpApp")," instances:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-bash"},"curl http://localhost:8081/foo/inc\ncurl http://localhost:8082/foo/inc\ncurl http://localhost:8083/foo/inc\n\ncurl http://localhost:8081/bar/inc\ncurl http://localhost:8082/bar/inc\ncurl http://localhost:8083/bar/inc\n")),(0,r.kt)("p",null,"At the same time, each entity is running only in one instance of ",(0,r.kt)("inlineCode",{parentName:"p"},"HttpApp"),". So if we send a request for an entity to one of the instances of ",(0,r.kt)("inlineCode",{parentName:"p"},"HttpApp")," where that entity doesn't belong, that request will be routed to the correct instance."),(0,r.kt)("h2",{id:"8-distributed-computing"},"8. Distributed Computing"),(0,r.kt)("p",null,"The most important feature of Akka is its distributed computing capabilities. It provides a set of well-established tools for building distributed systems, like Akka Cluster, Akka Distributed Data, Akka Remoting, Akka gRPC, etc."),(0,r.kt)("p",null,"ZIO has started a couple of projects to support distributed computing and there are also some community projects. However, some of them are still in the early stages of development. Hence, if you are heavily relying on distributed Akka technologies, you may need to make a decision with more caution."),(0,r.kt)("p",null,"In this section, we are going to iterate over the available options and what is the current progress:"),(0,r.kt)("p",null,"First of all, we have a production-ready project for gRPC called ",(0,r.kt)("a",{parentName:"p",href:"/ecosystem/community/zio-grpc"},"ZIO gRPC"),". It is a ZIO wrapper around ",(0,r.kt)("a",{parentName:"p",href:"https://scalapb.github.io/"},"ScalaPB"),". It also supports streaming RPC calls using ZIO Streams."),(0,r.kt)("p",null,"The next fantastic project is ",(0,r.kt)("a",{parentName:"p",href:"/zio-schema/"},"ZIO Schema"),". Using ZIO Schema, you can define your data types as schemas and then generate codecs for them. It also supports distributed computing by providing a way to serialize and deserialize computations. So we can both move data and computations over the network and execute them remotely."),(0,r.kt)("p",null,"Again, as we ",(0,r.kt)("a",{parentName:"p",href:"#entity-sharding-in-zio"},"mentioned")," in this article, if you need to scale out your application using Entity Sharding, you can use ",(0,r.kt)("a",{parentName:"p",href:"https://devsisters.github.io/shardcake/"},"ShardCake"),". It provides location transparency for your entities, and you can run them in a distributed manner."),(0,r.kt)("p",null,"ZIO has another project in development called ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/zio/zio-flow"},"ZIO Flow"),". It is a distributed workflow executor. We can think of ",(0,r.kt)("inlineCode",{parentName:"p"},"ZFlow")," as a distributed version of ",(0,r.kt)("inlineCode",{parentName:"p"},"ZIO"),". Using ",(0,r.kt)("inlineCode",{parentName:"p"},"ZFlow")," we can describe a distributed workflow without worrying about the underlying concerns like transactional guarantees, fault tolerance, manual retries, etc. It is still in the early stages of development and it is not ready for production use."),(0,r.kt)("p",null,(0,r.kt)("a",{parentName:"p",href:"https://zio.github.io/zio-keeper/"},"ZIO Keeper")," is another project in development. It aims to provide solutions for the following distributed computing problems:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},"Transport: A transport layer for sending and receiving messages between nodes. Currently, it supports unicast and broadcast messages."),(0,r.kt)("li",{parentName:"ul"},"Membership: A membership layer for discovering nodes that are part of the same distributed system and also providing algorithms for joining and leaving the cluster. Currently, it uses SWIM and HyParView algorithms."),(0,r.kt)("li",{parentName:"ul"},'Consensus: A consensus layer provides a solution for this problem: "What if the leader becomes unavailable?". Which is not developed yet.')),(0,r.kt)("p",null,"There is also a work-in-progress implementation of the Raft protocol called ",(0,r.kt)("a",{parentName:"p",href:"https://github.com/ariskk/zio-raft"},"ZIO Raft")," which is worth mentioning."))}m.isMDXComponent=!0}}]);