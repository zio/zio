"use strict";(self.webpackChunkzio_site=self.webpackChunkzio_site||[]).push([[63578],{3905:(e,t,n)=>{n.d(t,{Zo:()=>p,kt:()=>d});var a=n(67294);function r(e,t,n){return t in e?Object.defineProperty(e,t,{value:n,enumerable:!0,configurable:!0,writable:!0}):e[t]=n,e}function o(e,t){var n=Object.keys(e);if(Object.getOwnPropertySymbols){var a=Object.getOwnPropertySymbols(e);t&&(a=a.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),n.push.apply(n,a)}return n}function i(e){for(var t=1;t<arguments.length;t++){var n=null!=arguments[t]?arguments[t]:{};t%2?o(Object(n),!0).forEach((function(t){r(e,t,n[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(n)):o(Object(n)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(n,t))}))}return e}function s(e,t){if(null==e)return{};var n,a,r=function(e,t){if(null==e)return{};var n,a,r={},o=Object.keys(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||(r[n]=e[n]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(a=0;a<o.length;a++)n=o[a],t.indexOf(n)>=0||Object.prototype.propertyIsEnumerable.call(e,n)&&(r[n]=e[n])}return r}var l=a.createContext({}),m=function(e){var t=a.useContext(l),n=t;return e&&(n="function"==typeof e?e(t):i(i({},t),e)),n},p=function(e){var t=m(e.components);return a.createElement(l.Provider,{value:t},e.children)},u="mdxType",c={inlineCode:"code",wrapper:function(e){var t=e.children;return a.createElement(a.Fragment,{},t)}},h=a.forwardRef((function(e,t){var n=e.components,r=e.mdxType,o=e.originalType,l=e.parentName,p=s(e,["components","mdxType","originalType","parentName"]),u=m(n),h=r,d=u["".concat(l,".").concat(h)]||u[h]||c[h]||o;return n?a.createElement(d,i(i({ref:t},p),{},{components:n})):a.createElement(d,i({ref:t},p))}));function d(e,t){var n=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=n.length,i=new Array(o);i[0]=h;var s={};for(var l in t)hasOwnProperty.call(t,l)&&(s[l]=t[l]);s.originalType=e,s[u]="string"==typeof e?e:r,i[1]=s;for(var m=2;m<o;m++)i[m]=n[m];return a.createElement.apply(null,i)}return a.createElement.apply(null,n)}h.displayName="MDXCreateElement"},76097:(e,t,n)=>{n.r(t),n.d(t,{assets:()=>l,contentTitle:()=>i,default:()=>c,frontMatter:()=>o,metadata:()=>s,toc:()=>m});var a=n(87462),r=(n(67294),n(3905));const o={id:"operations",title:"Operations"},i=void 0,s={unversionedId:"reference/stream/zstream/operations",id:"reference/stream/zstream/operations",title:"Operations",description:"Tapping",source:"@site/docs/reference/stream/zstream/operations.md",sourceDirName:"reference/stream/zstream",slug:"/reference/stream/zstream/operations",permalink:"/reference/stream/zstream/operations",draft:!1,editUrl:"https://github.com/zio/zio/edit/series/2.x/docs/reference/stream/zstream/operations.md",tags:[],version:"current",frontMatter:{id:"operations",title:"Operations"},sidebar:"reference-sidebar",previous:{title:"Resourceful Streams",permalink:"/reference/stream/zstream/resourceful-streams"},next:{title:"Consuming Streams",permalink:"/reference/stream/zstream/consuming-streams"}},l={},m=[{value:"Tapping",id:"tapping",level:2},{value:"Taking Elements",id:"taking-elements",level:2},{value:"Mapping",id:"mapping",level:2},{value:"Filtering",id:"filtering",level:2},{value:"Scanning",id:"scanning",level:2},{value:"Draining",id:"draining",level:2},{value:"Changes",id:"changes",level:2},{value:"Collecting",id:"collecting",level:2},{value:"Zipping",id:"zipping",level:2},{value:"Cross Product",id:"cross-product",level:2},{value:"Partitioning",id:"partitioning",level:2},{value:"partition",id:"partition",level:3},{value:"partitionEither",id:"partitioneither",level:3},{value:"GroupBy",id:"groupby",level:2},{value:"groupByKey",id:"groupbykey",level:3},{value:"groupBy",id:"groupby-1",level:3},{value:"Grouping",id:"grouping",level:2},{value:"grouped",id:"grouped",level:3},{value:"groupedWithin",id:"groupedwithin",level:3},{value:"Concatenation",id:"concatenation",level:2},{value:"Merging",id:"merging",level:2},{value:"merge",id:"merge",level:3},{value:"Termination Strategy",id:"termination-strategy",level:3},{value:"mergeAll",id:"mergeall",level:3},{value:"mergeWith",id:"mergewith",level:3},{value:"Interleaving",id:"interleaving",level:2},{value:"Interspersing",id:"interspersing",level:2},{value:"Broadcasting",id:"broadcasting",level:2},{value:"Distribution",id:"distribution",level:2},{value:"Buffering",id:"buffering",level:2},{value:"Debouncing",id:"debouncing",level:2},{value:"Aggregation",id:"aggregation",level:2},{value:"Synchronous Aggregation",id:"synchronous-aggregation",level:3},{value:"Asynchronous Aggregation",id:"asynchronous-aggregation",level:3}],p={toc:m},u="wrapper";function c(e){let{components:t,...n}=e;return(0,r.kt)(u,(0,a.Z)({},p,n,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h2",{id:"tapping"},"Tapping"),(0,r.kt)("p",null,"Tapping is an operation of running an effect on each emission of the ZIO Stream. We can think of ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#tap")," as an operation that allows us to observe each element of the stream, do some effectful operation and discard the result of this observation. The ",(0,r.kt)("inlineCode",{parentName:"p"},"tap")," operation does not change elements of the stream, it does not affect the return type of the stream."),(0,r.kt)("p",null,"For example, we can print each element of a stream by using the ",(0,r.kt)("inlineCode",{parentName:"p"},"tap")," operation:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val stream: ZStream[Any, IOException, Int] =\n  ZStream(1, 2, 3)\n    .tap(x => printLine(s"before mapping: $x"))\n    .map(_ * 2)\n    .tap(x => printLine(s"after mapping: $x"))\n')),(0,r.kt)("h2",{id:"taking-elements"},"Taking Elements"),(0,r.kt)("p",null,"We can take a certain number of elements from a stream:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val stream = ZStream.iterate(0)(_ + 1)\nval s1 = stream.take(5)\n// Output: 0, 1, 2, 3, 4\n\nval s2 = stream.takeWhile(_ < 5)\n// Output: 0, 1, 2, 3, 4\n\nval s3 = stream.takeUntil(_ == 5)\n// Output: 0, 1, 2, 3, 4, 5\n\nval s4 = s3.takeRight(3)\n// Output: 3, 4, 5\n")),(0,r.kt)("h2",{id:"mapping"},"Mapping"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"map")," \u2014 Applies a given function to all element of this stream to produce another stream:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"import zio.stream._\n\nval intStream: UStream[Int] = ZStream.fromIterable(0 to 100)\nval stringStream: UStream[String] = intStream.map(_.toString)\n")),(0,r.kt)("p",null,"If our transformation is effectful, we can use ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#mapZIO")," instead."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"mapZIOPar")," \u2014  It is similar to ",(0,r.kt)("inlineCode",{parentName:"p"},"mapZIO"),", but will evaluate effects in parallel. It will emit the results downstream in the original order. The ",(0,r.kt)("inlineCode",{parentName:"p"},"n")," argument specifies the number of concurrent running effects."),(0,r.kt)("p",null,"Let's write a simple page downloader, which download URLs concurrently:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"def fetchUrl(url: URL): Task[String] = ZIO.succeed(???)\ndef getUrls: Task[List[URL]] = ZIO.succeed(???)\n\nval pages = ZStream.fromIterableZIO(getUrls).mapZIOPar(8)(fetchUrl)  \n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"mapChunk")," \u2014 Each stream is backed by some ",(0,r.kt)("inlineCode",{parentName:"p"},"Chunk"),"s. By using ",(0,r.kt)("inlineCode",{parentName:"p"},"mapChunk")," we can batch the underlying stream and map every ",(0,r.kt)("inlineCode",{parentName:"p"},"Chunk")," at once:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val chunked = \n  ZStream\n    .fromChunks(Chunk(1, 2, 3), Chunk(4, 5), Chunk(6, 7, 8, 9))\n\nval stream = chunked.mapChunks(x => x.tail)\n\n// Input:  1, 2, 3, 4, 5, 6, 7, 8, 9\n// Output:    2, 3,    5,    7, 8, 9\n")),(0,r.kt)("p",null,"If our transformation is effectful we can use ",(0,r.kt)("inlineCode",{parentName:"p"},"mapChunksZIO")," combinator."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"mapAccum")," \u2014 It is similar to a ",(0,r.kt)("inlineCode",{parentName:"p"},"map"),", but it ",(0,r.kt)("strong",{parentName:"p"},"transforms elements statefully"),". ",(0,r.kt)("inlineCode",{parentName:"p"},"mapAccum")," allows us to ",(0,r.kt)("em",{parentName:"p"},"map")," and ",(0,r.kt)("em",{parentName:"p"},"accumulate")," in the same operation."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"abstract class ZStream[-R, +E, +O] {\n  def mapAccum[S, O1](s: S)(f: (S, O) => (S, O1)): ZStream[R, E, O1]\n}\n")),(0,r.kt)("p",null,"Let's write a transformation, which calculate ",(0,r.kt)("em",{parentName:"p"},"running total")," of input stream:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"def runningTotal(stream: UStream[Int]): UStream[Int] =\n  stream.mapAccum(0)((acc, next) => (acc + next, acc + next))\n\n// input:  0, 1, 2, 3,  4,  5\n// output: 0, 1, 3, 6, 10, 15\n")),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"mapConcat")," \u2014 It is similar to ",(0,r.kt)("inlineCode",{parentName:"p"},"map"),", but maps each element to zero or more elements with the type of ",(0,r.kt)("inlineCode",{parentName:"p"},"Iterable")," and then flattens the whole stream:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val numbers: UStream[Int] = \n  ZStream("1-2-3", "4-5", "6")\n    .mapConcat(_.split("-"))\n    .map(_.toInt)\n\n// Input:  "1-2-3", "4-5", "6"\n// Output: 1, 2, 3, 4, 5, 6\n')),(0,r.kt)("p",null,"The effectful version of ",(0,r.kt)("inlineCode",{parentName:"p"},"mapConcat")," is ",(0,r.kt)("inlineCode",{parentName:"p"},"mapConcatZIO"),"."),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"ZStream")," also has chunked versions of that which are ",(0,r.kt)("inlineCode",{parentName:"p"},"mapConcatChunk")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"mapConcatChunkZIO"),"."),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"as")," \u2014 The ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#as")," method maps the success values of this stream to the specified constant value."),(0,r.kt)("p",null,"For example, we can map all element to the unit value:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val unitStream: ZStream[Any, Nothing, Unit] = \n  ZStream.range(1, 5).as(())\n")),(0,r.kt)("h2",{id:"filtering"},"Filtering"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#filter")," allows us to filter emitted elements:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val s1 = ZStream.range(1, 11).filter(_ % 2 == 0)\n// Output: 2, 4, 6, 8, 10\n\n// The `ZStream#withFilter` operator enables us to write filter in for-comprehension style\nval s2 = for {\n  i <- ZStream.range(1, 11).take(10)\n  if i % 2 == 0\n} yield i\n// Output: 2, 4, 6, 8, 10\n\nval s3 = ZStream.range(1, 11).filterNot(_ % 2 == 0)\n// Output: 1, 3, 5, 7, 9\n")),(0,r.kt)("h2",{id:"scanning"},"Scanning"),(0,r.kt)("p",null,"Scans are like folds, but with a history. Like folds, they take a binary operator with an initial value. A fold combines elements of a stream and emits every intermediary result as an output of the stream:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val scan = ZStream(1, 2, 3, 4, 5).scan(0)(_ + _)\n// Output: 0, 1, 3, 6, 10\n// Iterations:\n//        =>  0 (initial value)\n//  0 + 1 =>  1\n//  1 + 2 =>  3\n//  3 + 3 =>  6\n//  6 + 4 => 10\n// 10 + 5 => 15\n\nval fold = ZStream(1, 2, 3, 4, 5).runFold(0)(_ + _)\n// Output: 10 (ZIO effect containing 10)\n")),(0,r.kt)("h2",{id:"draining"},"Draining"),(0,r.kt)("p",null,"Assume we have an effectful stream, which contains a sequence of effects; sometimes we might want to execute its effect without emitting any element, in these situations to discard the results we should use the ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#drain")," method. It removes all output values from the stream:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val s1: ZStream[Any, Nothing, Nothing] = ZStream(1, 2, 3, 4, 5).drain\n// Emitted Elements: <empty stream, it doesn't emit any element>\n\nval s2: ZStream[Any, IOException, Int] =\n  ZStream\n    .repeatZIO {\n      for {\n        nextInt <- Random.nextInt\n        number = Math.abs(nextInt % 10)\n        _ <- Console.printLine(s\"random number: $number\")\n      } yield (number)\n    }\n    .take(3)\n// Emitted Elements: 1, 4, 7\n// Result of Stream Effect on the Console:\n// random number: 1\n// random number: 4\n// random number: 7\n\nval s3: ZStream[Any, IOException, Nothing] = s2.drain\n// Emitted Elements: <empty stream, it doesn't emit any element>\n// Result of Stream Effect on the Console:\n// random number: 4\n// random number: 8\n// random number: 2\n")),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#drain")," often used with ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#merge")," to run one side of the merge for its effect while getting outputs from the opposite side of the merge:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val logging = ZStream.fromZIO(\n  printLine("Starting to merge with the next stream")\n)\nval stream = ZStream(1, 2, 3) ++ logging.drain ++ ZStream(4, 5, 6)\n\n// Emitted Elements: 1, 2, 3, 4, 5, 6\n// Result of Stream Effect on the Console:\n// Starting to merge with the next stream\n')),(0,r.kt)("p",null,"Note that if we do not drain the ",(0,r.kt)("inlineCode",{parentName:"p"},"logging")," stream, the emitted elements would be contained unit value:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val stream = ZStream(1, 2, 3) ++ logging ++ ZStream(4, 5, 6)\n\n// Emitted Elements: 1, 2, 3, (), 4, 5, 6\n// Result of Stream Effect on the Console:\n// Starting to merge with the next stream\n")),(0,r.kt)("h2",{id:"changes"},"Changes"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#changes")," emits elements that are not equal to the previous element:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val changes = ZStream(1, 1, 1, 2, 2, 3, 4).changes\n// Output: 1, 2, 3, 4\n")),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#changes")," operator, uses natural equality to determine whether two elements are equal. If we prefer the specialized equality checking, we can provide a function of type ",(0,r.kt)("inlineCode",{parentName:"p"},"(O, O) => Boolean")," to the ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#changesWith")," operator."),(0,r.kt)("p",null,"Assume we have a stream of events with a composite key of ",(0,r.kt)("em",{parentName:"p"},"partition")," and ",(0,r.kt)("em",{parentName:"p"},"offset")," attributes, and we know that the offset is monotonic in each partition. So, we can use the ",(0,r.kt)("inlineCode",{parentName:"p"},"changesWith")," operator to create a stream of unique elements:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"case class Event(partition: Long, offset: Long, metadata: String) \nval events: ZStream[Any, Nothing, Event] = ZStream.fromIterable(???)\n\nval uniques = events.changesWith((e1, e2) => (e1.partition == e2.partition && e1.offset == e2.offset))\n")),(0,r.kt)("h2",{id:"collecting"},"Collecting"),(0,r.kt)("p",null,"We can perform ",(0,r.kt)("inlineCode",{parentName:"p"},"filter")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"map")," operations in a single step using the ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#collect")," operation:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val source1 = ZStream(1, 2, 3, 4, 0, 5, 6, 7, 8)\n  \nval s1 = source1.collect { case x if x < 6 => x * 2 }\n// Output: 2, 4, 6, 8, 0, 10\n\nval s2 = source1.collectWhile { case x if x != 0 => x * 2 }\n// Output: 2, 4, 6, 8\n\nval source2 = ZStream(Left(1), Right(2), Right(3), Left(4), Right(5))\n\nval s3 = source2.collectLeft\n// Output: 1, 4\n\nval s4 = source2.collectWhileLeft\n// Output: 1\n\nval s5 = source2.collectRight\n// Output: 2, 3, 5\n\nval s6 = source2.drop(1).collectWhileRight\n// Output: 2, 3\n\nval s7 = source2.map(_.toOption).collectSome\n// Output: 2, 3, 5\n\nval s8 = source2.map(_.toOption).collectWhileSome\n// Output: empty stream\n")),(0,r.kt)("p",null,"We can also do effectful collect using ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#collectZIO")," and ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#collectWhileZIO"),"."),(0,r.kt)("p",null,"ZIO stream has ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#collectSuccess")," which helps us to perform effectful operations and just collect the success values:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val urls = ZStream(\n  "dotty.epfl.ch",\n  "zio.dev",\n  "zio.github.io/zio-json",\n  "zio.github.io/zio-nio/"\n)\n\ndef fetch(url: String): ZIO[Any, Throwable, String] = \n  ZIO.attemptBlocking(???)\n\nval pages = urls\n  .mapZIO(url => fetch(url).exit)\n  .collectSuccess\n')),(0,r.kt)("h2",{id:"zipping"},"Zipping"),(0,r.kt)("p",null,"We can zip two stream by using ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream.zip")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#zipWith")," operator:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val s1: UStream[(Int, String)] =\n  ZStream(1, 2, 3, 4, 5, 6).zipWith(ZStream("a", "b", "c"))((a, b) => (a, b))\n\nval s2: UStream[(Int, String)] = \n  ZStream(1, 2, 3, 4, 5, 6).zip(ZStream("a", "b", "c"))\n  \n// Output: (1, "a"), (2, "b"), (3, "c")\n')),(0,r.kt)("p",null,"The new stream will end when one of the streams ends."),(0,r.kt)("p",null,"In case of ending one stream before another, we might need to zip with default values; the ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#zipAll")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#zipAllWith")," takes default values of both sides to perform such mechanism for us:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val s1 = ZStream(1, 2, 3)\n  .zipAll(ZStream("a", "b", "c", "d", "e"))(0, "x")\nval s2 = ZStream(1, 2, 3).zipAllWith(\n  ZStream("a", "b", "c", "d", "e")\n)(_ => 0, _ => "x")((a, b) => (a, b))\n\n// Output: (1, a), (2, b), (3, c), (0, d), (0, e)\n')),(0,r.kt)("p",null,"Sometimes we want to zip streams, but do not want to zip two elements one by one. For example, we may have two streams producing elements at different speeds, and do not want to wait for the slower one when zipping elements. When we need to zip elements with the latest element of the slower stream, ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#zipLatest")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#zipLatestWith")," will do this for us. It zips two streams so that when a value is emitted by either of the two streams, it is combined with the latest value from the other stream to produce a result:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val s1 = ZStream(1, 2, 3)\n  .schedule(Schedule.spaced(1.second))\n\nval s2 = ZStream("a", "b", "c", "d")\n  .schedule(Schedule.spaced(500.milliseconds))\n  .rechunk(3)\n\ns1.zipLatest(s2)\n\n// Output: (1, a), (1, b), (1, c), (1, d), (2, d), (3, d)\n')),(0,r.kt)("p",null,"ZIO Stream also has three useful operators for zipping element of a stream with their previous/next elements and also both of them:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val stream: UStream[Int] = ZStream.fromIterable(1 to 5)\n\nval s1: UStream[(Option[Int], Int)]              = stream.zipWithPrevious\nval s2: UStream[(Int, Option[Int])]              = stream.zipWithNext\nval s3: UStream[(Option[Int], Int, Option[Int])] = stream.zipWithPreviousAndNext\n")),(0,r.kt)("p",null,"By using ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#zipWithIndex")," we can index elements of a stream:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val indexedStream: ZStream[Any, Nothing, (String, Long)] = \n  ZStream("Mary", "James", "Robert", "Patricia").zipWithIndex\n\n// Output: ("Mary", 0L), ("James", 1L), ("Robert", 2L), ("Patricia", 3L)\n')),(0,r.kt)("h2",{id:"cross-product"},"Cross Product"),(0,r.kt)("p",null,"ZIO stream has ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStram#cross")," and its variants to compute ",(0,r.kt)("em",{parentName:"p"},"Cartesian Product")," of two streams:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val first = ZStream(1, 2, 3)\nval second = ZStream("a", "b")\n\nval s1 = first cross second\nval s2 = first <*> second\nval s3 = first.crossWith(second)((a, b) => (a, b))\n// Output: (1,a), (1,b), (2,a), (2,b), (3,a), (3,b)\n\nval s4 = first crossLeft second \nval s5 = first <* second\n// Keep only elements from the left stream\n// Output: 1, 1, 2, 2, 3, 3 \n\nval s6 = first crossRight second\nval s7 = first *> second\n// Keep only elements from the right stream\n// Output: a, b, a, b, a, b\n')),(0,r.kt)("p",null,"Note that the right-hand side stream would be run multiple times, for every element in the left stream."),(0,r.kt)("p",null,"ZIO stream also has ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream.crossN")," which takes streams up to four one."),(0,r.kt)("h2",{id:"partitioning"},"Partitioning"),(0,r.kt)("h3",{id:"partition"},"partition"),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#partition")," function splits the stream into tuple of streams based on the predicate. The first stream contains all element evaluated to true, and the second one contains all element evaluated to false."),(0,r.kt)("p",null,"The faster stream may advance by up to ",(0,r.kt)("inlineCode",{parentName:"p"},"buffer")," elements further than the slower one. Two streams are wrapped by ",(0,r.kt)("inlineCode",{parentName:"p"},"Scope")," type."),(0,r.kt)("p",null,"In the example below, left stream consists of even numbers only:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val partitionResult: ZIO[Scope, Nothing, (ZStream[Any, Nothing, Int], ZStream[Any, Nothing, Int])] =\n  ZStream\n    .fromIterable(0 to 100)\n    .partition(_ % 2 == 0, buffer = 50)\n")),(0,r.kt)("h3",{id:"partitioneither"},"partitionEither"),(0,r.kt)("p",null,"If we need to partition a stream using an effectful predicate we can use ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream.partitionEither"),"."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"abstract class ZStream[-R, +E, +O] {\n  final def partitionEither[R1 <: R, E1 >: E, O2, O3](\n    p: O => ZIO[R1, E1, Either[O2, O3]],\n    buffer: Int = 16\n  ): ZIO[R1 with Scope, E1, (ZStream[Any, E1, O2], ZStream[Any, E1, O3])]\n}\n")),(0,r.kt)("p",null,"Here is a simple example of using this function:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val partitioned: ZIO[Scope, Nothing, (ZStream[Any, Nothing, Int], ZStream[Any, Nothing, Int])] =\n  ZStream\n    .fromIterable(1 to 10)\n    .partitionEither(x => ZIO.succeed(if (x < 5) Left(x) else Right(x)))\n")),(0,r.kt)("h2",{id:"groupby"},"GroupBy"),(0,r.kt)("h3",{id:"groupbykey"},"groupByKey"),(0,r.kt)("p",null,"To partition the stream by function result we can use ",(0,r.kt)("inlineCode",{parentName:"p"},"groupBy")," by providing a function of type ",(0,r.kt)("inlineCode",{parentName:"p"},"O => K")," which determines by which keys the stream should be partitioned."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"abstract class ZStream[-R, +E, +O] {\n  final def groupByKey[K](\n    f: O => K,\n    buffer: Int = 16\n  ): ZStream.GroupBy[R, E, K, O]\n}\n")),(0,r.kt)("p",null,"In the example below, exam results are grouped into buckets and counted:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'import zio._\nimport zio.stream._\n\n  case class Exam(person: String, score: Int)\n\n  val examResults = Seq(\n    Exam("Alex", 64),\n    Exam("Michael", 97),\n    Exam("Bill", 77),\n    Exam("John", 78),\n    Exam("Bobby", 71)\n  )\n\n  val groupByKeyResult: ZStream[Any, Nothing, (Int, Int)] =\n    ZStream\n      .fromIterable(examResults)\n      .groupByKey(exam => exam.score / 10 * 10) {\n        case (k, s) => ZStream.fromZIO(s.runCollect.map(l => k -> l.size))\n      }\n')),(0,r.kt)("admonition",{type:"note"},(0,r.kt)("p",{parentName:"admonition"},(0,r.kt)("inlineCode",{parentName:"p"},"groupByKey")," partition the stream by a simple function of type ",(0,r.kt)("inlineCode",{parentName:"p"},"O => K"),"; It is not an effectful function. In some cases we need to partition the stream by using an ",(0,r.kt)("em",{parentName:"p"},"effectful function")," of type ",(0,r.kt)("inlineCode",{parentName:"p"},"O => ZIO[R1, E1, (K, V)]"),"; So we can use ",(0,r.kt)("inlineCode",{parentName:"p"},"groupBy")," which is the powerful version of ",(0,r.kt)("inlineCode",{parentName:"p"},"groupByKey")," function.")),(0,r.kt)("h3",{id:"groupby-1"},"groupBy"),(0,r.kt)("p",null,"It takes an effectful function of type ",(0,r.kt)("inlineCode",{parentName:"p"},"O => ZIO[R1, E1, (K, V)]"),"; ZIO Stream uses this function to partition the stream and gives us a new data type called ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream.GroupBy")," which represent a grouped stream. ",(0,r.kt)("inlineCode",{parentName:"p"},"GroupBy")," has an ",(0,r.kt)("inlineCode",{parentName:"p"},"apply")," method, that takes a function of type ",(0,r.kt)("inlineCode",{parentName:"p"},"(K, ZStream[Any, E, V]) => ZStream[R1, E1, A]"),"; ZIO Runtime runs this function across all groups and then merges them in a non-deterministic fashion as a result."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"abstract class ZStream[-R, +E, +O] {\n  final def groupBy[R1 <: R, E1 >: E, K, V](\n    f: O => ZIO[R1, E1, (K, V)],\n    buffer: Int = 16\n  ): ZStream.GroupBy[R1, E1, K, V]\n}\n")),(0,r.kt)("p",null,"In the example below, we are going ",(0,r.kt)("inlineCode",{parentName:"p"},"groupBy")," given names by their first character and then count the number of names in each group:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val counted: UStream[(Char, Long)] =\n  ZStream("Mary", "James", "Robert", "Patricia", "John", "Jennifer", "Rebecca", "Peter")\n    .groupBy(x => ZIO.succeed((x.head, x))) { case (char, stream) =>\n      ZStream.fromZIO(stream.runCount.map(count => char -> count))\n    }\n// Input:  Mary, James, Robert, Patricia, John, Jennifer, Rebecca, Peter\n// Output: (P, 2), (R, 2), (M, 1), (J, 3)\n')),(0,r.kt)("p",null,"Let's change the above example a bit into an example of classifying students. The teacher assigns the student to a specific class based on the student's talent. Note that the partitioning operation is an effectful:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val classifyStudents: ZStream[Any, IOException, (String, Seq[String])] =\n  ZStream.fromZIO(\n    printLine("Please assign each student to one of the A, B, or C classrooms.")\n  ) *> ZStream("Mary", "James", "Robert", "Patricia", "John", "Jennifer", "Rebecca", "Peter")\n    .groupBy(student =>\n      printLine(s"What is the classroom of $student? ") *>\n        readLine.map(classroom => (classroom, student))\n    ) { case (classroom, students) =>\n      ZStream.fromZIO(\n        students\n          .runFold(Seq.empty[String])((s, e) => s :+ e)\n          .map(students => classroom -> students)\n      )\n    }\n\n// Input: \n// Please assign each student to one of the A, B, or C classrooms.\n// What is the classroom of Mary? A\n// What is the classroom of James? B\n// What is the classroom of Robert? A\n// What is the classroom of Patricia? C\n// What is the classroom of John? B\n// What is the classroom of Jennifer? A\n// What is the classroom of Rebecca? C\n// What is the classroom of Peter? A\n//\n// Output: \n// (B,List(James, John))\n// (A,List(Mary, Robert, Jennifer, Peter))\n// (C,List(Patricia, Rebecca))\n')),(0,r.kt)("h2",{id:"grouping"},"Grouping"),(0,r.kt)("h3",{id:"grouped"},"grouped"),(0,r.kt)("p",null,"To partition the stream results with the specified chunk size, we can use the ",(0,r.kt)("inlineCode",{parentName:"p"},"grouped")," function."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val groupedResult: ZStream[Any, Nothing, Chunk[Int]] =\n  ZStream.fromIterable(0 to 8).grouped(3)\n\n// Input:  0, 1, 2, 3, 4, 5, 6, 7, 8\n// Output: Chunk(0, 1, 2), Chunk(3, 4, 5), Chunk(6, 7, 8)\n")),(0,r.kt)("h3",{id:"groupedwithin"},"groupedWithin"),(0,r.kt)("p",null,"It allows grouping events by time or chunk size, whichever is satisfied first. In the example below every chunk consists of 30 elements and is produced every 3 seconds."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"import zio._\nimport zio.Duration._\nimport zio.stream._\n\nval groupedWithinResult: ZStream[Any, Nothing, Chunk[Int]] =\n  ZStream.fromIterable(0 to 10)\n    .repeat(Schedule.spaced(1.seconds))\n    .groupedWithin(30, 10.seconds)\n")),(0,r.kt)("h2",{id:"concatenation"},"Concatenation"),(0,r.kt)("p",null,"We can concatenate two streams by using ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#++")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#concat")," operator which returns a stream that emits the elements from the left-hand stream and then emits the elements from the right stream:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala",metastring:"silent:nest","silent:nest":!0},"val a = ZStream(1, 2, 3)\nval b = ZStream(4, 5)\nval c1 = a ++ b\nval c2 = a concat b\n")),(0,r.kt)("p",null,"Also, we can use ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream.concatAll")," constructor to concatenate given streams together:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val c3 = ZStream.concatAll(Chunk(a, b))\n")),(0,r.kt)("p",null,"There is also the ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#flatMap")," combinator which create a stream which elements are generated by applying a function of type ",(0,r.kt)("inlineCode",{parentName:"p"},"O => ZStream[R1, E1, O2]")," to each output of the source stream and concatenated all of the results:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val stream = ZStream(1, 2, 3).flatMap(x => ZStream.repeat(x).take(4))\n// Input:  1, 2, 3\n// Output: 1, 1, 1, 1, 2, 2, 2, 2, 3, 3, 3, 3\n")),(0,r.kt)("p",null,"Assume we have an API that takes an author name and returns all its book:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"def getAuthorBooks(author: String): ZStream[Any, Throwable, Book] = ZStream(???)\n")),(0,r.kt)("p",null,"If we have a stream of author's names, we can use ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#flatMap")," to concatenate the results of all API calls:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val authors: ZStream[Any, Throwable, String] = \n  ZStream("Mary", "James", "Robert", "Patricia", "John")\nval allBooks: ZStream[Any, Throwable, Book]  = \n  authors.flatMap(getAuthorBooks _)\n')),(0,r.kt)("p",null,"If we need to do the ",(0,r.kt)("inlineCode",{parentName:"p"},"flatMap")," concurrently, we can use ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#flatMapPar"),", and also if the order of concatenation is not important for us, we can use the ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#flatMapParSwitch")," operator."),(0,r.kt)("h2",{id:"merging"},"Merging"),(0,r.kt)("p",null,"Sometimes we need to interleave the emission of two streams and create another stream. In these cases, we can't use the ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream.concat")," operation because the ",(0,r.kt)("inlineCode",{parentName:"p"},"concat")," operation waits for the first stream to finish and then consumes the second stream. So we need a non-deterministic way of picking elements from different sources. ZIO Stream's ",(0,r.kt)("inlineCode",{parentName:"p"},"merge")," operations does this for us. Let's discuss some variants of this operation:"),(0,r.kt)("h3",{id:"merge"},"merge"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"ZSstream#merge")," picks elements randomly from specified streams:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val s1 = ZStream(1, 2, 3).rechunk(1)\nval s2 = ZStream(4, 5, 6).rechunk(1)\n\nval merged = s1 merge s2\n// As the merge operation is not deterministic, it may output the following stream of numbers:\n// Output: 4, 1, 2, 5, 6, 3\n")),(0,r.kt)("p",null,"Merge operation always try to pull one chunk from each stream, if we chunk our streams equal or over 3 elements in the last example, we encounter a new stream containing one of the ",(0,r.kt)("inlineCode",{parentName:"p"},"1, 2, 3, 4, 5, 6")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"4, 5, 6, 1, 2, 3")," elements."),(0,r.kt)("h3",{id:"termination-strategy"},"Termination Strategy"),(0,r.kt)("p",null,"When we merge two streams, we should think about the ",(0,r.kt)("em",{parentName:"p"},"termination strategy")," of this operation. Each stream has a specific lifetime. One stream may emit all its elements and finish its job, another stream may end after one hour of emission, one another may have a long-running lifetime and never end. So when we merge two streams with different lifetimes, what is the termination strategy of the resulting stream?"),(0,r.kt)("p",null,"By default, when we merge two streams using ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#merge")," operation, the newly produced stream will terminate when both specified streams terminate. We can also define the ",(0,r.kt)("em",{parentName:"p"},"termination strategy")," corresponding to our requirement. ZIO Stream supports four different termination strategies:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Left")," \u2014 The resulting stream will terminate when the left-hand side stream terminates."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Right")," \u2014 The resulting stream will terminate when the right-hand side stream finishes."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Both")," \u2014 The resulting stream will terminate when both streams finish."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Either")," \u2014 The resulting stream will terminate when one of the streams finishes.")),(0,r.kt)("p",null,"Here is an example of specifying termination strategy when merging two streams:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"import zio.stream.ZStream.HaltStrategy\nval s1 = ZStream.iterate(1)(_+1).take(5).rechunk(1)\nval s2 = ZStream.repeat(0).rechunk(1)\n\nval merged = s1.merge(s2, HaltStrategy.Left)\n")),(0,r.kt)("p",null,"We can also use ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#mergeTerminateLeft"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#mergeTerminateRight")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#mergeTerminateEither")," operations instead of specifying manually the termination strategy."),(0,r.kt)("h3",{id:"mergeall"},"mergeAll"),(0,r.kt)("p",null,"Usually, micro-services or long-running applications are composed of multiple components that need to run infinitely in the background and if something happens to them, or they terminate abruptly we should crash the entire application."),(0,r.kt)("p",null,"So our main fiber should perform these three things:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Launch and wait")," \u2014 It should launch all of those background components and wait infinitely. It should not exit prematurely, because then our application won't be running."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Interrupt everything")," \u2014 It should interrupt all those components whenever we receive a termination signal from the operating system."),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Watch all fibers")," \u2014 It should watch all those fibers (background components), and quickly exit if something goes wrong.")),(0,r.kt)("p",null,"So how should we do that with our main fiber? Let's try to create a long-running application:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val main = \n  kafkaConsumer.runDrain.fork *>\n  httpServer.fork *>\n  scheduledJobRunner.fork *>\n  ZIO.never\n")),(0,r.kt)("p",null,"We can launch the Kafka consumer, the HTTP server, and our job runner and fork them, and then wait using ",(0,r.kt)("inlineCode",{parentName:"p"},"ZIO.never"),". This will indeed wait, but if something happens to any of them and if they crash, nothing happens. So our application just hangs and remains up without anything working in the background. So this approach does not work properly."),(0,r.kt)("p",null,"So another idea is to watch background components. By using ",(0,r.kt)("inlineCode",{parentName:"p"},"ZIO.raceFirst")," as soon as one of those fibers terminates with either success or failure, it will interrupt all the rest of the components:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val main =\n  ZIO.raceFirst(kafkaConsumer.runDrain, List(httpServer, scheduledJobRunner))\n")),(0,r.kt)("p",null,"We can also do this with streams:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val main =\n  for {\n  //_ <- other resources\n    _ <- ZStream\n      .mergeAllUnbounded(16)(\n        kafkaConsumer.drain,\n        ZStream.fromZIO(httpServer),\n        ZStream.fromZIO(scheduledJobRunner)\n      )\n      .runDrain\n  } yield ()\n")),(0,r.kt)("p",null,"Using ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream.mergeAll")," we can combine all these streaming components concurrently into one application."),(0,r.kt)("h3",{id:"mergewith"},"mergeWith"),(0,r.kt)("p",null,"Sometimes we need to merge two streams and after that, unify them and convert them to new element types. We can do this by using the ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#mergeWith")," operation:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val s1 = ZStream("1", "2", "3")\nval s2 = ZStream(4.1, 5.3, 6.2)\n\nval merged = s1.mergeWith(s2)(_.toInt, _.toInt)\n')),(0,r.kt)("h2",{id:"interleaving"},"Interleaving"),(0,r.kt)("p",null,"When we ",(0,r.kt)("inlineCode",{parentName:"p"},"merge")," two streams, the ZIO Stream picks elements from two streams randomly. But how to merge two streams deterministically? The answer is the ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#interleave")," operation."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#interleave")," operator pulls an element from each stream, one by one, and then returns an interleaved stream. When one stream is exhausted, all remaining values in the other stream will be pulled:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val s1 = ZStream(1, 2, 3)\nval s2 = ZStream(4, 5, 6, 7, 8)\n\nval interleaved = s1 interleave s2\n\n// Output: 1, 4, 2, 5, 3, 6, 7, 8\n")),(0,r.kt)("p",null,"ZIO Stream also has the ",(0,r.kt)("inlineCode",{parentName:"p"},"interleaveWith")," operator, which is a more powerful version of ",(0,r.kt)("inlineCode",{parentName:"p"},"interleave"),". By using ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#interleaveWith"),", we can specify the logic of interleaving:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val s1 = ZStream(1, 3, 5, 7, 9)\nval s2 = ZStream(2, 4, 6, 8, 10)\n\nval interleaved = s1.interleaveWith(s2)(ZStream(true, false, false).forever)\n// Output: 1, 2, 4, 3, 6, 8, 5, 10, 7, 9\n")),(0,r.kt)("p",null,(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#interleaveWith")," uses a stream of boolean to decide which stream to choose. If it reaches a true value, it will pick a value from the left-hand side stream, otherwise, it will pick from the right-hand side."),(0,r.kt)("h2",{id:"interspersing"},"Interspersing"),(0,r.kt)("p",null,"We can intersperse any stream by using ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#intersperse")," operator:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val s1 = ZStream(1, 2, 3, 4, 5).intersperse(0)\n// Output: 1, 0, 2, 0, 3, 0, 4, 0, 5\n\nval s2 = ZStream("a", "b", "c", "d").intersperse("[", "-", "]")\n// Output: [, -, a, -, b, -, c, -, d]\n')),(0,r.kt)("h2",{id:"broadcasting"},"Broadcasting"),(0,r.kt)("p",null,"We can broadcast a stream by using ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#broadcast"),", it returns a scoped list of streams that have the same elements as the source stream. The ",(0,r.kt)("inlineCode",{parentName:"p"},"broadcast")," operation emits each element to the inputs of returning streams. The upstream stream can emit events as much as ",(0,r.kt)("inlineCode",{parentName:"p"},"maximumLag"),", then it decreases its speed by the slowest downstream stream."),(0,r.kt)("p",null,"In the following example, we are broadcasting stream of random numbers to the two downstream streams. One of them is responsible to compute the maximum number, and the other one does some logging job with additional delay. The upstream stream decreases its speed by the logging stream:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val stream: ZIO[Any, IOException, Unit] =\n  ZIO.scoped {\n    ZStream\n      .fromIterable(1 to 20)\n      .mapZIO(_ => Random.nextInt)\n      .map(Math.abs)\n      .map(_ % 100)\n      .tap(e => printLine(s"Emit $e element before broadcasting"))\n      .broadcast(2, 5)\n      .flatMap { streams =>\n          for {\n            out1 <- streams(0).runFold(0)((acc, e) => Math.max(acc, e))\n                      .flatMap(x => printLine(s"Maximum: $x"))\n                      .fork\n            out2 <- streams(1).schedule(Schedule.spaced(1.second))\n                      .foreach(x => printLine(s"Logging to the Console: $x"))\n                      .fork\n            _    <- out1.join.zipPar(out2.join)\n          } yield ()\n      }\n  }\n')),(0,r.kt)("h2",{id:"distribution"},"Distribution"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#distributedWith")," operator is a more powerful version of ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#broadcast"),". It takes a ",(0,r.kt)("inlineCode",{parentName:"p"},"decide")," function, and based on that decide how to distribute incoming elements into the downstream streams:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"abstract class ZStream[-R, +E, +O] {\n  final def distributedWith[E1 >: E](\n    n: Int,\n    maximumLag: Int,\n    decide: O => UIO[Int => Boolean]\n  ): ZIO[R with Scope, Nothing, List[Dequeue[Exit[Option[E1], O]]]] = ???\n}\n")),(0,r.kt)("p",null,"In the example below, we are partitioning incoming elements into three streams using ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#distributedWith")," operator:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val partitioned: ZIO[Scope, Nothing, (UStream[Int], UStream[Int], UStream[Int])] =\n  ZStream\n    .iterate(1)(_ + 1)\n    .schedule(Schedule.fixed(1.seconds))\n    .distributedWith(3, 10, x => ZIO.succeed(q => x % 3 == q))\n    .flatMap { \n      case q1 :: q2 :: q3 :: Nil =>\n        ZIO.succeed(\n          ZStream.fromQueue(q1).flattenExitOption,\n          ZStream.fromQueue(q2).flattenExitOption,\n          ZStream.fromQueue(q3).flattenExitOption\n        )\n      case _ => ZIO.dieMessage("Impossible!")\n    }\n')),(0,r.kt)("h2",{id:"buffering"},"Buffering"),(0,r.kt)("p",null,"Since the ZIO streams are pull-based, it means the consumers do not need to message the upstream to slow down. Whenever a downstream stream pulls a new element, the upstream produces a new element. So, the upstream stream is as fast as the slowest downstream stream. Sometimes we need to run producer and consumer independently, in such a situation we can use an asynchronous non-blocking queue for communication between faster producer and slower consumer; the queue can buffer elements between two streams. ZIO stream also has a built-in ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#buffer")," operator which does the same thing for us."),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#buffer")," allows a faster producer to progress independently of a slower consumer by buffering up to ",(0,r.kt)("inlineCode",{parentName:"p"},"capacity")," chunks in a queue."),(0,r.kt)("p",null,"In the following example, we are going to buffer a stream. We print each element to the console as they are emitting before and after the buffering:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'ZStream\n  .fromIterable(1 to 10)\n  .rechunk(1)\n  .tap(x => Console.printLine(s"before buffering: $x"))\n  .buffer(4)\n  .tap(x => Console.printLine(s"after buffering: $x"))\n  .schedule(Schedule.spaced(5.second))  \n')),(0,r.kt)("p",null,"We spaced 5 seconds between each emission to show the lag between producing and consuming messages."),(0,r.kt)("p",null,"Based on the type of underlying queue we can use one the buffering operators:"),(0,r.kt)("ul",null,(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Bounded Queue")," \u2014 ",(0,r.kt)("inlineCode",{parentName:"li"},"ZStream#buffer(capacity: Int)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Unbounded Queue")," \u2014 ",(0,r.kt)("inlineCode",{parentName:"li"},"ZStream#bufferUnbounded")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Sliding Queue")," \u2014 ",(0,r.kt)("inlineCode",{parentName:"li"},"ZStream#bufferSliding(capacity: Int)")),(0,r.kt)("li",{parentName:"ul"},(0,r.kt)("strong",{parentName:"li"},"Dropping Queue")," ",(0,r.kt)("inlineCode",{parentName:"li"},"ZStream#bufferDropping(capacity: Int)"))),(0,r.kt)("h2",{id:"debouncing"},"Debouncing"),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#debounce")," method debounces the stream with a minimum period of ",(0,r.kt)("inlineCode",{parentName:"p"},"d")," between each element:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val stream = (\n  ZStream(1, 2, 3) ++\n    ZStream.fromZIO(ZIO.sleep(500.millis)) ++ ZStream(4, 5) ++\n    ZStream.fromZIO(ZIO.sleep(10.millis)) ++\n    ZStream(6)\n).debounce(100.millis) // emit only after a pause of at least 100 ms\n// Output: 3, 6\n")),(0,r.kt)("h2",{id:"aggregation"},"Aggregation"),(0,r.kt)("p",null,"Aggregation is the process of converting one or more elements of type ",(0,r.kt)("inlineCode",{parentName:"p"},"A")," into elements of type ",(0,r.kt)("inlineCode",{parentName:"p"},"B"),". This operation takes a transducer as an aggregation unit and returns another stream that is aggregated. We have two types of aggregation:"),(0,r.kt)("h3",{id:"synchronous-aggregation"},"Synchronous Aggregation"),(0,r.kt)("p",null,"They are synchronous because the upstream emits an element when the ",(0,r.kt)("em",{parentName:"p"},"transducer")," emits one. To apply a synchronous aggregation to the stream we can use ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#aggregate")," or ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#transduce")," operations."),(0,r.kt)("p",null,"Let's see an example of synchronous aggregation:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val stream = ZStream(1, 2, 3, 4, 5, 6, 7, 8, 9, 10)\nval s1 = stream.transduce(ZSink.collectAllN[Int](3))\n// Output Chunk(1,2,3), Chunk(4,5,6), Chunk(7,8,9), Chunk(10)\n")),(0,r.kt)("p",null,"Sometimes stream processing element by element is not efficient, specially when we are working with files or doing I/O works; so we might need to aggregate them and process them in a batch way:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},'val source =\n  ZStream\n    .iterate(1)(_ + 1)\n    .take(200)\n    .tap(x =>\n      printLine(s"Producing Element $x")\n        .schedule(Schedule.duration(1.second).jittered)\n    )\n\nval sink = \n  ZSink.foreach((e: Chunk[Int]) =>\n    printLine(s"Processing batch of events: $e")\n      .schedule(Schedule.duration(3.seconds).jittered)\n  )\n  \nval myApp = \n  source.transduce(ZSink.collectAllN[Int](5)).run(sink)\n')),(0,r.kt)("p",null,"Let's see one output of running this program:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Producing element 1\nProducing element 2\nProducing element 3\nProducing element 4\nProducing element 5\nProcessing batch of events: Chunk(1,2,3,4,5)\nProducing element 6\nProducing element 7\nProducing element 8\nProducing element 9\nProducing element 10\nProcessing batch of events: Chunk(6,7,8,9,10)\nProducing element 11\nProducing element 12\nProcessing batch of events: Chunk(11,12)\n")),(0,r.kt)("p",null,"Elements are grouped into Chunks of 5 elements and then processed in a batch way."),(0,r.kt)("h3",{id:"asynchronous-aggregation"},"Asynchronous Aggregation"),(0,r.kt)("p",null,"Asynchronous aggregations, aggregate elements of upstream as long as the downstream operators are busy. To apply an asynchronous aggregation to the stream, we can use ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#aggregateAsync"),", ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#aggregateAsyncWithin"),", and ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#aggregateAsyncWithinEither")," operations."),(0,r.kt)("p",null,"For example, consider ",(0,r.kt)("inlineCode",{parentName:"p"},"source.aggregateAsync(ZSink.collectAllN[Nothing, Int](5)).mapZIO(processChunks)"),". Whenever the downstream (",(0,r.kt)("inlineCode",{parentName:"p"},"mapZIO(processChunks)"),") is ready for consumption and pulls the upstream, the transducer ",(0,r.kt)("inlineCode",{parentName:"p"},"(ZTransducer.collectAllN(5))")," will flush out its buffer, regardless of whether the ",(0,r.kt)("inlineCode",{parentName:"p"},"collectAllN")," buffered all its 5 elements or not. So the ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#aggregateAsync")," will emit when downstream pulls:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val myApp = \n  source.aggregateAsync(ZSink.collectAllN[Int](5)).run(sink)\n")),(0,r.kt)("p",null,"Let's see one output of running this program:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre"},"Producing element 1\nProducing element 2\nProducing element 3\nProducing element 4\nProcessing batch of events: Chunk(1,2)\nProcessing batch of events: Chunk(3,4)\nProducing element 5\nProcessing batch of events: Chunk(5)\nProducing element 6\nProcessing batch of events: Chunk(6)\nProducing element 7\nProducing element 8\nProducing element 9\nProcessing batch of events: Chunk(7)\nProducing element 10\nProducing element 11\nProcessing batch of events: Chunk(8,9)\nProducing element 12\nProcessing batch of events: Chunk(10,11)\nProcessing batch of events: Chunk(12)\n")),(0,r.kt)("p",null,"The ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#aggregateAsyncWithin")," is another aggregator which takes a scheduler. This scheduler will consume all events produced by the given transducer. So the ",(0,r.kt)("inlineCode",{parentName:"p"},"aggregateAsyncWithin")," will emit when the transducer emits or when the scheduler expires:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"abstract class ZStream[-R, +E, +O] {\n  final def aggregateAsyncWithin[R1 <: R, E1 >: E, E2, A1 >: A, B](\n    sink: ZSink[R1, E1, A1, E2, A1, B],\n    schedule: Schedule[R1, Option[B], Any]\n  )(implicit trace: Trace): ZStream[R1, E2, B] = ???\n}\n")),(0,r.kt)("p",null,"When we are doing I/O, batching is very important. With ZIO streams, we can create user-defined batches. It is pretty easy to do that with the ",(0,r.kt)("inlineCode",{parentName:"p"},"ZStream#aggregateAsyncWithin")," operator. Let's see the below snippet code:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"dataStream.aggregateAsyncWithin(\n   ZSink.collectAllN[Record](2000),\n   Schedule.fixed(30.seconds)\n )\n")),(0,r.kt)("p",null,"So it will collect elements into a chunk up to 2000 elements and if we have got less than 2000 elements and 30 seconds have passed, it will pass currently collected elements down the stream whether it has collected zero, one, or 2000 elements. So this is a sort of timeout for aggregation operation. This approach aggressively favors ",(0,r.kt)("strong",{parentName:"p"},"throughput")," over ",(0,r.kt)("strong",{parentName:"p"},"latency"),". It will introduce a fixed amount of latency into a stream. We will always wait for up to 30 seconds if we haven't reached this sort of boundary value."),(0,r.kt)("p",null,"Instead, thanks to ",(0,r.kt)("inlineCode",{parentName:"p"},"Schedule")," we can create a much smarter ",(0,r.kt)("strong",{parentName:"p"},"adaptive batching algorithm")," that can balance between ",(0,r.kt)("strong",{parentName:"p"},"throughput")," and *",(0,r.kt)("em",{parentName:"p"},"latency"),". So what we are doing here is that we are creating a schedule that operates on chunks of records. What the ",(0,r.kt)("inlineCode",{parentName:"p"},"Schedule")," does is that it starts off with 30-second timeouts for as long as its input has a size that is lower than 1000, now once we see an input that has a size look higher than 1000, we will switch to a second schedule with some jittery, and we will remain with this schedule for as long as the batch size is over 1000:"),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-scala"},"val schedule: Schedule[Any, Option[Chunk[Record]], Long] =\n// Start off with 30-second timeouts as long as the batch size is < 1000\n  Schedule.fixed(30.seconds).whileInput[Option[Chunk[Record]]](_.getOrElse(Chunk.empty).length < 100) andThen\n    // and then, switch to a shorter jittered schedule for as long as batches remain over 1000\n    Schedule.fixed(5.seconds).jittered.whileInput[Option[Chunk[Record]]](_.getOrElse(Chunk.empty).length >= 1000)\n    \ndataStream\n  .aggregateAsyncWithin(ZSink.collectAllN[Record](2000), schedule)\n")))}c.isMDXComponent=!0}}]);